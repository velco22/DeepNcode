{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Computation of the quantization process MNIST int8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import netron\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:32.063228Z",
     "end_time": "2023-04-07T21:38:36.527123Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (eva_images, eva_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images_float32 = train_images.astype(np.float32) / 255.0\n",
    "eva_images_float32 = eva_images.astype(np.float32) / 255.0\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 255.\n",
    "train_images_uint8 = train_images.astype(np.uint8)\n",
    "eva_images_uint8 = eva_images.astype(np.uint8)\n",
    "\n",
    "# # Normalize the input image so that each pixel value is between -128 and 127.\n",
    "train_images_int8 = np.int8(train_images.astype(np.float32) - 128.0)\n",
    "eva_images_int8 = np.int8(eva_images.astype(np.float32) - 128.0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:36.523122Z",
     "end_time": "2023-04-07T21:38:36.978280Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(60000, 28, 28) (60000,)\n",
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images_float32.shape, train_labels.shape)\n",
    "print(train_images_uint8.shape, train_labels.shape)\n",
    "print(train_images_int8.shape, train_labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:36.973199Z",
     "end_time": "2023-04-07T21:38:36.994047Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images_float32:\n",
      " [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.31764707 0.9411765  0.99215686 0.99215686 0.46666667\n",
      " 0.09803922 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ] \n",
      "-----------\n",
      "train_images_uint8:\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "  25   0   0   0   0   0   0   0   0   0] \n",
      "-----------\n",
      "train_images_int8:\n",
      " [-128 -128 -128 -128 -128 -128 -128 -128 -128 -128 -128 -128 -128  -47\n",
      "  112  125  125   -9 -103 -128 -128 -128 -128 -128 -128 -128 -128 -128] \n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "print(f'train_images_float32:\\n {train_images_float32[0][14]} \\n-----------')\n",
    "print(f'train_images_uint8:\\n {train_images_uint8[0][14]} \\n-----------')\n",
    "print(f'train_images_int8:\\n {train_images_int8[0][14]} \\n-----------')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:36.986495Z",
     "end_time": "2023-04-07T21:38:37.030785Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 3 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(train_images_int8[i], cmap=\"gray\")\n",
    "    plt.xlabel(train_labels[i])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:37.003765Z",
     "end_time": "2023-04-07T21:38:37.205177Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reshape data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size: 28, input_size: 784\n",
      "train_images_float32.shape: (60000, 784)\n",
      "train_images_uint8.shape: (60000, 784)\n",
      "train_images_int8.shape: (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# image dimensions (assumed square)\n",
    "image_size = train_images_float32.shape[1]\n",
    "input_size = image_size * image_size\n",
    "print(f'image_size: {image_size}, input_size: {input_size}')\n",
    "\n",
    "#reshape data to fit model\n",
    "train_images_float32 = np.reshape(train_images_float32, [-1, input_size])\n",
    "eva_images_float32 = np.reshape(eva_images_float32, [-1, input_size])\n",
    "\n",
    "train_images_uint8 = np.reshape(train_images_uint8, [-1, input_size])\n",
    "eva_images_uint8 = np.reshape(eva_images_uint8, [-1, input_size])\n",
    "\n",
    "train_images_int8 = np.reshape(train_images_int8, [-1, input_size])\n",
    "eva_images_int8 = np.reshape(eva_images_int8, [-1, input_size])\n",
    "\n",
    "print(f'train_images_float32.shape: {train_images_float32.shape}')\n",
    "print(f'train_images_uint8.shape: {train_images_uint8.shape}')\n",
    "print(f'train_images_int8.shape: {train_images_int8.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:37.207176Z",
     "end_time": "2023-04-07T21:38:37.294391Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Crate nn model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                15700     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,910\n",
      "Trainable params: 15,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4704 - accuracy: 0.8720 - val_loss: 0.2645 - val_accuracy: 0.9254\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2457 - accuracy: 0.9302 - val_loss: 0.2310 - val_accuracy: 0.9311\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2063 - accuracy: 0.9401 - val_loss: 0.1998 - val_accuracy: 0.9396\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1795 - accuracy: 0.9485 - val_loss: 0.1783 - val_accuracy: 0.9480\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1611 - accuracy: 0.9534 - val_loss: 0.1687 - val_accuracy: 0.9514\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1481 - accuracy: 0.9567 - val_loss: 0.1554 - val_accuracy: 0.9548\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1383 - accuracy: 0.9595 - val_loss: 0.1523 - val_accuracy: 0.9550\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1305 - accuracy: 0.9620 - val_loss: 0.1446 - val_accuracy: 0.9587\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1242 - accuracy: 0.9637 - val_loss: 0.1468 - val_accuracy: 0.9590\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1184 - accuracy: 0.9654 - val_loss: 0.1409 - val_accuracy: 0.9599\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2469aae9088>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(20, activation='relu', input_dim=input_size),\n",
    "    tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(\n",
    "    train_images_float32,\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_data=(eva_images_float32, eva_labels)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:37.221519Z",
     "end_time": "2023-04-07T21:38:48.805001Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# save float weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "tflite_models_dir = pathlib.Path(\"models\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "float_weights_path = r\"./models/mnist_float_nn_tf/mnist_float_weights\"\n",
    "\n",
    "# Save the model:\n",
    "float_weights_model_file = tflite_models_dir / \"mnist_float_nn_tf/mnist_float_weights\"\n",
    "float_weights_model_file_index = tflite_models_dir / \"mnist_float_nn_tf/mnist_float_weights.index\"\n",
    "if not float_weights_model_file_index.is_file():\n",
    "    model.save_weights(float_weights_model_file)\n",
    "    print(\"Float weights saved to: \", float_weights_model_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:48.805001Z",
     "end_time": "2023-04-07T21:38:48.819223Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load float weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 20)                15700     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,910\n",
      "Trainable params: 15,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None \n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "first_layer_weights:\n",
      " [[-0.05734742  0.03238516 -0.0131309  ...  0.0538438   0.06947835\n",
      "  -0.08367986]\n",
      " [-0.04574046  0.01396968  0.03617882 ...  0.08624725 -0.00907713\n",
      "   0.02075221]\n",
      " [-0.0462221  -0.01265661 -0.02388771 ...  0.01787594  0.05865231\n",
      "  -0.02859867]\n",
      " ...\n",
      " [ 0.08237264  0.05092688 -0.0561528  ...  0.05016512 -0.06105468\n",
      "  -0.0708051 ]\n",
      " [ 0.01267599 -0.00062798  0.03164186 ... -0.08033977  0.03497818\n",
      "  -0.04936257]\n",
      " [-0.07966912  0.00122225  0.01436885 ...  0.0019754  -0.03939991\n",
      "   0.07504976]] \n",
      "-----------\n",
      "first_layer_biases:\n",
      " [-0.0180229  -0.05185258 -0.07380836 -0.06695198 -0.51160127 -0.03668379\n",
      " -0.04722319  0.03628216  0.05233814  0.3702851  -0.12966041 -0.2395938\n",
      "  0.12044918 -0.07785489  0.00470146 -0.08835129  0.7251768   0.11014404\n",
      "  0.3813814   0.24397661] \n",
      "-----------\n",
      "-----------\n",
      "second_layer_weights:\n",
      " [[-0.14898142  0.11176224 -0.18184839  0.01475042 -1.3020742   0.8911642\n",
      "   0.4506968   0.35559794 -0.6825692   0.29967   ]\n",
      " [ 0.30354506 -1.2575797  -0.49922714  0.09171315  0.26948544 -0.21767972\n",
      "  -0.05040022  0.4497028   0.5669265  -0.02249288]\n",
      " [ 0.18492776 -0.41283646 -0.05077624 -0.09359017 -0.0918397   0.25278127\n",
      "   0.6508589  -0.62917227  0.24681503 -1.0154036 ]\n",
      " [ 0.28749537 -0.42829025 -0.17855944 -0.263233   -0.2001618   0.5816766\n",
      "   0.52557003 -0.7747826  -0.06378494  0.4804278 ]\n",
      " [ 0.38530543  0.24177484  0.2786974  -0.00772023 -0.84185416 -0.5448636\n",
      "   0.46916416 -0.3635583   0.1671324   0.34700316]\n",
      " [-0.3061627   0.700827    0.48937836 -0.7005312   0.24280655  0.06576189\n",
      "   0.01269353 -0.58230585  0.46637616  0.35609108]\n",
      " [ 0.40202528  0.55720055  0.52929235 -0.43660465  0.2940682  -0.42981356\n",
      "   0.09468375 -0.31770453 -0.5535658   0.5891131 ]\n",
      " [ 0.12353495  0.5655566  -0.03858546  0.5065713  -0.6062107   0.27961892\n",
      "  -0.47189295  0.10151479  0.4562366   0.08250338]\n",
      " [-0.9581498   0.58648497  0.6651573   0.5265609  -0.5867176  -0.03293226\n",
      "   0.06797066  0.49474686 -0.40565455 -0.7732925 ]\n",
      " [ 0.0799716   0.3356234   0.1128471   0.25455517 -0.00155973 -0.1851727\n",
      "   0.6763234   0.09741738 -0.6959262  -1.3255944 ]\n",
      " [ 0.14019953 -0.38556352 -1.0292182  -1.0430739   0.17855032  0.28404453\n",
      "   0.5628663   0.26253572 -0.12117667  0.18916303]\n",
      " [ 0.12976398  0.16296323 -0.01159878  0.3126462   0.546798   -1.2633878\n",
      "  -0.42265695  0.44269794 -0.05562312  0.707389  ]\n",
      " [-0.5118954  -0.05814311 -0.32845026  0.48216608 -0.08906322 -0.23051296\n",
      "  -1.1491957   0.04459784 -0.46486366  0.5442692 ]\n",
      " [-0.5657534  -0.7050618   0.63420194  0.22712292  0.32133728  0.29722074\n",
      "   0.28738973 -0.5642939   0.6523944  -0.20696469]\n",
      " [ 0.21137293 -0.3098802  -0.13420956  0.31605205  0.32178643  0.04884663\n",
      "   0.05562724 -1.1449679   0.05626617 -0.46083325]\n",
      " [-0.1936861  -0.44014257  0.4367897   0.400708   -0.86027527  0.51569635\n",
      "  -1.0818942  -0.43304172 -0.23770985 -0.4904236 ]\n",
      " [ 0.21535096 -0.45608985 -0.00529958 -0.3071444   0.20741658  0.53229195\n",
      "  -0.35369784  0.5564315  -0.2591222   0.04390877]\n",
      " [-0.4020325   0.3596244   0.96913415 -0.29651996  0.5089108   0.0119906\n",
      "   0.153572   -0.66312295 -0.6129849   0.578082  ]\n",
      " [-0.8628167   0.50079125 -0.40329042 -0.33602753  0.26502192 -0.4045243\n",
      "  -0.01535754  0.4175777   0.24802491 -0.03905395]\n",
      " [ 0.40067425 -0.7292119   0.2254473  -0.2243573  -0.5358094  -0.12744993\n",
      "  -0.3729982   0.6164847  -0.39772326 -0.38605994]] \n",
      "-----------\n",
      "second_layer_biases:\n",
      " [-0.19449125  0.41917142 -0.16768914 -0.21250191  0.19403027  0.38531384\n",
      " -0.19261985  0.3959989  -0.3675089  -0.27362648] \n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.load_weights(float_weights_model_file)\n",
    "\n",
    "print(model.summary(), '\\n-----------------------------------------\\n-----------------------------------------\\n-----------------------------------------')\n",
    "first_layer_weights = model.layers[0].get_weights()[0]\n",
    "first_layer_biases  = model.layers[0].get_weights()[1]\n",
    "second_layer_weights = model.layers[1].get_weights()[0]\n",
    "second_layer_biases  = model.layers[1].get_weights()[1]\n",
    "\n",
    "print(f'first_layer_weights:\\n {first_layer_weights} \\n-----------')\n",
    "print(f'first_layer_biases:\\n {first_layer_biases} \\n-----------\\n-----------')\n",
    "print(f'second_layer_weights:\\n {second_layer_weights} \\n-----------')\n",
    "print(f'second_layer_biases:\\n {second_layer_biases} \\n-----------')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:48.819223Z",
     "end_time": "2023-04-07T21:38:48.873562Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "if not pathlib.Path(float_weights_path + r'_details.txt').is_file():\n",
    "\n",
    "    with open(float_weights_path + r'_details.txt', 'w') as f:\n",
    "        first_layer_weights = model.layers[0].get_weights()[0]\n",
    "        first_layer_biases  = model.layers[0].get_weights()[1]\n",
    "        second_layer_weights = model.layers[1].get_weights()[0]\n",
    "        second_layer_biases  = model.layers[1].get_weights()[1]\n",
    "\n",
    "        np.array2string(np.array(first_layer_weights), threshold=np.inf, max_line_width=np.inf, separator=\", \")\n",
    "\n",
    "        f.write(f'first_layer_weights:\\n {np.array2string(np.array(first_layer_weights), threshold=np.inf, max_line_width=np.inf, separator=\", \")} \\n-----------\\n')\n",
    "        f.write(f'first_layer_biases:\\n {np.array2string(np.array(first_layer_biases), threshold=np.inf, max_line_width=np.inf, separator=\", \")} \\n-----------\\n-----------\\n')\n",
    "        f.write(f'second_layer_weights:\\n {np.array2string(np.array(second_layer_weights), threshold=np.inf, max_line_width=np.inf, separator=\", \")} \\n-----------\\n')\n",
    "        f.write(f'second_layer_biases:\\n {np.array2string(np.array(second_layer_biases), threshold=np.inf, max_line_width=np.inf, separator=\", \")} \\n-----------\\n')\n",
    "\n",
    "    print('Details saved to: ', float_weights_path + r'_details.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:48.870553Z",
     "end_time": "2023-04-07T21:38:48.910830Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find out intermediate layer output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 574us/step\n"
     ]
    }
   ],
   "source": [
    "# Define a new model that outputs the intermediate layer\n",
    "intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
    "\n",
    "# Get the intermediate output for the entire input dataset\n",
    "intermediate_output_float32 = intermediate_model.predict(train_images_float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:48.886122Z",
     "end_time": "2023-04-07T21:38:50.405951Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 632us/step\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "outputs_float32 = model.predict(train_images_float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:50.400946Z",
     "end_time": "2023-04-07T21:38:51.876181Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert nn to int8 quantized model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Patrik\\AppData\\Local\\Temp\\tmpzvj67l7n\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dp\\dp\\code\\openvino_notebooks_py37\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in train_images_float32:\n",
    "        yield [input_value]\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Set the input and output tensors to int8\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:51.877180Z",
     "end_time": "2023-04-07T21:38:52.743391Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# save q model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "tflite_models_dir = pathlib.Path(\"models\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "model_path = r\"models/mnist_int8_tflite_model\"\n",
    "\n",
    "# Save the model:\n",
    "int8_tflite_model_file = tflite_models_dir / \"mnist_int8_tflite_model.tflite\"\n",
    "if not int8_tflite_model_file.is_file():\n",
    "    int8_tflite_model_file.write_bytes(tflite_model_quant)\n",
    "    print(\"Model saved to: \", int8_tflite_model_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:52.747391Z",
     "end_time": "2023-04-07T21:38:52.759512Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'models/mnist_int8_tflite_model.tflite' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": "('localhost', 8080)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netron.start(model_path + r'.tflite')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:52.761757Z",
     "end_time": "2023-04-07T21:38:52.837637Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load interpreter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "if not pathlib.Path(model_path + r'_details.txt').is_file():\n",
    "\n",
    "    interpreter_saved_details = tf.lite.Interpreter(model_path=model_path + r'.tflite')\n",
    "    interpreter_saved_details.allocate_tensors()\n",
    "\n",
    "    input_index = interpreter_saved_details.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter_saved_details.get_output_details()[0][\"index\"]\n",
    "    input_details = interpreter_saved_details.get_input_details()[0]\n",
    "\n",
    "    test_image = eva_images_float32[0]\n",
    "    print(eva_labels[0])\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to int8\n",
    "    if input_details[\"dtype\"] == np.int8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter_saved_details.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter_saved_details.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest probability.\n",
    "    output = interpreter_saved_details.get_tensor(output_index)\n",
    "    digit = np.argmax(output[0])\n",
    "    print(f'output: {output} \\n digit: {digit} \\n')\n",
    "\n",
    "    with open(model_path + r'_details.txt', 'w') as f:\n",
    "        f.write('Tensor details:\\n\\n')\n",
    "        for dict in interpreter_saved_details.get_tensor_details():\n",
    "            i = dict['index']\n",
    "            tensor_name = dict['name']\n",
    "            scales = dict['quantization_parameters']['scales']\n",
    "            zero_points = dict['quantization_parameters']['zero_points']\n",
    "\n",
    "            flag_tenstor = True\n",
    "            try:\n",
    "                tensor = interpreter_saved_details.tensor(i)()\n",
    "                tensor_arr = np.array(tensor)\n",
    "            except:\n",
    "                flag_tenstor = False\n",
    "\n",
    "            type = dict['dtype']\n",
    "\n",
    "            f.write(\n",
    "                f'{i} {type} {tensor_name} \\n scales:\\n {scales} \\n zero_points:\\n {zero_points} \\n tensor_shape:\\n {tensor.shape}\\n tensor:\\n '\n",
    "                f'{np.array2string(tensor_arr, threshold=np.inf, max_line_width=np.inf, separator=\", \") if flag_tenstor else \"Tensor data is null\" }\\n')\n",
    "            f.write(\n",
    "                '\\n\\n------------------------------------------------------------------------------------------------------------------------\\n\\n')\n",
    "\n",
    "        for item in interpreter_saved_details.get_tensor_details():\n",
    "            f.write(str(item).replace('{\\'name', '\\n{\\'name'))\n",
    "\n",
    "    print('Details saved to: ', model_path + r'_details.txt')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:52.843216Z",
     "end_time": "2023-04-07T21:38:52.883409Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "tf.quantization.quantize"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:52.854864Z",
     "end_time": "2023-04-07T21:38:52.929370Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Calculation of a, b parameters\n",
    "\n",
    "def calculation_a_b(input_array):\n",
    "    return np.min(input_array), np.max(input_array)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Weight quantization\n",
    "\n",
    "def weight_scaling_factor(a, b, min_T, max_T):\n",
    "    s_a = a / min_T\n",
    "    s_b = b / max_T\n",
    "\n",
    "    if s_a > s_b:\n",
    "        return s_a, a, max_T * s_a\n",
    "    else:\n",
    "        return s_b, min_T * s_b, b\n",
    "\n",
    "def clamp(r,a,b):\n",
    "    return min(max(r, a), b)\n",
    "\n",
    "def weight_quan(r, a, b, min_T, s):\n",
    "\n",
    "    q_value = np.round((clamp(r,a,b) - a) / s) + min_T\n",
    "\n",
    "    # print(f'q_value: {q_value}')\n",
    "\n",
    "    z = 0\n",
    "    r = s * (q_value - z)\n",
    "\n",
    "    # print(f'r: {r}')\n",
    "\n",
    "    return q_value\n",
    "\n",
    "def weight_arr_quan(input_arr, min_T, max_T):\n",
    "\n",
    "    a, b = calculation_a_b(input_arr)\n",
    "    s, a, b = weight_scaling_factor(a, b, min_T, max_T)\n",
    "\n",
    "    out_arr = np.zeros(input_arr.shape, dtype=np.int8).T\n",
    "\n",
    "    for i in range(input_arr.shape[0]):\n",
    "        for j in range(input_arr.shape[1]):\n",
    "            out_arr[j][i] = weight_quan(input_arr[i][j], a, b, min_T, s)\n",
    "\n",
    "    return s, 0, out_arr\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Activation quantization\n",
    "\n",
    "def activation_scaling_factor(a, b, n):\n",
    "   return (b - a) / (n - 1)\n",
    "\n",
    "def activation_scale_zero_point(input_array, n):\n",
    "    a, b = calculation_a_b(input_array)\n",
    "    s = activation_scaling_factor(a, b, n)\n",
    "    q_value = np.round((0 - a) / s) - n/2\n",
    "    z = q_value - (0 / s)\n",
    "\n",
    "    print(f's: {s} \\nz: {z}')\n",
    "\n",
    "    return s, z\n",
    "\n",
    "def activation_quan(r, a, b, n, s, z):\n",
    "\n",
    "    q_value = np.round((clamp(r,a,b) - a) / s) - n/2\n",
    "\n",
    "    print(f'q_value: {q_value}')\n",
    "\n",
    "    r = s * (q_value - z)\n",
    "    print(f'r: {r}')\n",
    "\n",
    "    return q_value\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Bias quantization\n",
    "\n",
    "def bias_quan(r, s_w, s_i):\n",
    "    return np.round(r / (s_i * s_w))\n",
    "\n",
    "def bias_arr_quan(arr, s_w, s_i):\n",
    "\n",
    "    arr = np.array([bias_quan(r, s_w, s_i) for r in arr], dtype=np.int32)\n",
    "    s = s_w * s_i\n",
    "\n",
    "    return s, 0, arr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:52.877899Z",
     "end_time": "2023-04-07T21:38:52.933277Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.00629058031496063, -0.7989037, 0.7989037)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_scaling_factor(-0.7989037, 0.7096706, -127, 127)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:52.888410Z",
     "end_time": "2023-04-07T21:38:52.934274Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "-127.0"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_quan(0, -0.7989037, 0.7096706, -127, 127)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:52.903708Z",
     "end_time": "2023-04-07T21:38:52.991858Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "-122.0"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_quan(-0.0049962, 0.00392157, 0.01043775)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:52.918240Z",
     "end_time": "2023-04-07T21:38:52.995806Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 0.0 b: 1.0\n"
     ]
    }
   ],
   "source": [
    "a, b = calculation_a_b(train_images_float32)\n",
    "print(f'a: {a} b: {b}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:52.936285Z",
     "end_time": "2023-04-07T21:38:52.998233Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0009513237775275001,\n 0,\n array([-204,  441, -176, -223,  204,  405, -202,  416, -386, -288]))"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [-0.19449125,  0.41917142, -0.16768914, -0.21250191,  0.19403027,  0.38531384, -0.19261985,  0.3959989 , -0.3675089 , -0.27362648]\n",
    "\n",
    "bias_arr_quan(arr, 0.09114261, 0.01043775)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:52.977967Z",
     "end_time": "2023-04-07T21:38:52.998233Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 10)\n"
     ]
    }
   ],
   "source": [
    "arr_w = np. array([[-0.14898142,  0.11176224, -0.18184839,  0.01475042, -1.3020742 ,  0.8911642 ,  0.4506968 ,  0.35559794, -0.6825692 ,  0.29967   ],\n",
    " [ 0.30354506, -1.2575797 , -0.49922714,  0.09171315,  0.26948544, -0.21767972, -0.05040022,  0.4497028 ,  0.5669265 , -0.02249288],\n",
    " [ 0.18492776, -0.41283646, -0.05077624, -0.09359017, -0.0918397 ,  0.25278127,  0.6508589 , -0.62917227,  0.24681503, -1.0154036 ],\n",
    " [ 0.28749537, -0.42829025, -0.17855944, -0.263233  , -0.2001618 ,  0.5816766 ,  0.52557003, -0.7747826 , -0.06378494,  0.4804278 ],\n",
    " [ 0.38530543,  0.24177484,  0.2786974 , -0.00772023, -0.84185416, -0.5448636 ,  0.46916416, -0.3635583 ,  0.1671324 ,  0.34700316],\n",
    " [-0.3061627 ,  0.700827  ,  0.48937836, -0.7005312 ,  0.24280655,  0.06576189,  0.01269353, -0.58230585,  0.46637616,  0.35609108],\n",
    " [ 0.40202528,  0.55720055,  0.52929235, -0.43660465,  0.2940682 , -0.42981356,  0.09468375, -0.31770453, -0.5535658 ,  0.5891131 ],\n",
    " [ 0.12353495,  0.5655566 , -0.03858546,  0.5065713 , -0.6062107 ,  0.27961892, -0.47189295,  0.10151479,  0.4562366 ,  0.08250338],\n",
    " [-0.9581498 ,  0.58648497,  0.6651573 ,  0.5265609 , -0.5867176 , -0.03293226,  0.06797066,  0.49474686, -0.40565455, -0.7732925 ],\n",
    " [ 0.0799716 ,  0.3356234 ,  0.1128471 ,  0.25455517, -0.00155973, -0.1851727 ,  0.6763234 ,  0.09741738, -0.6959262 , -1.3255944 ],\n",
    " [ 0.14019953, -0.38556352, -1.0292182 , -1.0430739 ,  0.17855032,  0.28404453,  0.5628663 ,  0.26253572, -0.12117667,  0.18916303],\n",
    " [ 0.12976398,  0.16296323, -0.01159878,  0.3126462 ,  0.546798  , -1.2633878 , -0.42265695,  0.44269794, -0.05562312,  0.707389  ],\n",
    " [-0.5118954 , -0.05814311, -0.32845026,  0.48216608, -0.08906322, -0.23051296, -1.1491957 ,  0.04459784, -0.46486366,  0.5442692 ],\n",
    " [-0.5657534 , -0.7050618 ,  0.63420194,  0.22712292,  0.32133728,  0.29722074,  0.28738973, -0.5642939 ,  0.6523944 , -0.20696469],\n",
    " [ 0.21137293, -0.3098802 , -0.13420956,  0.31605205,  0.32178643,  0.04884663,  0.05562724, -1.1449679 ,  0.05626617, -0.46083325],\n",
    " [-0.1936861 , -0.44014257,  0.4367897 ,  0.400708  , -0.86027527,  0.51569635, -1.0818942 , -0.43304172, -0.23770985, -0.4904236 ],\n",
    " [ 0.21535096, -0.45608985, -0.00529958, -0.3071444 ,  0.20741658,  0.53229195, -0.35369784,  0.5564315 , -0.2591222 ,  0.04390877],\n",
    " [-0.4020325 ,  0.3596244 ,  0.96913415, -0.29651996,  0.5089108 ,  0.0119906 ,  0.153572  , -0.66312295, -0.6129849 ,  0.578082  ],\n",
    " [-0.8628167 ,  0.50079125, -0.40329042, -0.33602753,  0.26502192, -0.4045243 , -0.01535754,  0.4175777 ,  0.24802491, -0.03905395],\n",
    " [ 0.40067425, -0.7292119 ,  0.2254473 , -0.2243573 , -0.5358094 , -0.12744993, -0.3729982 ,  0.6164847 , -0.39772326, -0.38605994]])\n",
    "\n",
    "print(arr_w.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:53.006256Z",
     "end_time": "2023-04-07T21:38:53.010701Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.010437751181102363,\n 0,\n array([[ -14,   29,   18,   28,   37,  -29,   39,   12,  -92,    8,   13,\n           12,  -49,  -54,   20,  -19,   21,  -39,  -83,   38],\n        [  11, -120,  -40,  -41,   23,   67,   53,   54,   56,   32,  -37,\n           16,   -6,  -68,  -30,  -42,  -44,   34,   48,  -70],\n        [ -17,  -48,   -5,  -17,   27,   47,   51,   -4,   64,   11,  -99,\n           -1,  -31,   61,  -13,   42,   -1,   93,  -39,   22],\n        [   1,    9,   -9,  -25,   -1,  -67,  -42,   49,   50,   24, -100,\n           30,   46,   22,   30,   38,  -29,  -28,  -32,  -21],\n        [-125,   26,   -9,  -19,  -81,   23,   28,  -58,  -56,    0,   17,\n           52,   -9,   31,   31,  -82,   20,   49,   25,  -51],\n        [  85,  -21,   24,   56,  -52,    6,  -41,   27,   -3,  -18,   27,\n         -121,  -22,   28,    5,   49,   51,    1,  -39,  -12],\n        [  43,   -5,   62,   50,   45,    1,    9,  -45,    7,   65,   54,\n          -40, -110,   28,    5, -104,  -34,   15,   -1,  -36],\n        [  34,   43,  -60,  -74,  -35,  -56,  -30,   10,   47,    9,   25,\n           42,    4,  -54, -110,  -41,   53,  -64,   40,   59],\n        [ -65,   54,   24,   -6,   16,   45,  -53,   44,  -39,  -67,  -12,\n           -5,  -45,   63,    5,  -23,  -25,  -59,   24,  -38],\n        [  29,   -2,  -97,   46,   33,   34,   56,    8,  -74, -127,   18,\n           68,   52,  -20,  -44,  -47,    4,   55,   -4,  -37]], dtype=int8))"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_arr_quan(arr_w, -127, 127)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:53.009322Z",
     "end_time": "2023-04-07T21:38:53.083354Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:53.026182Z",
     "end_time": "2023-04-07T21:38:53.085334Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: 0.00392156862745098 \n",
      "z: -128.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.00392156862745098, -128.0)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_scale_zero_point(train_images_float32, 256)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:53.042180Z",
     "end_time": "2023-04-07T21:38:53.097796Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 20)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_output_float32.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:53.089300Z",
     "end_time": "2023-04-07T21:38:53.104633Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: 0.09114260206035539 \n",
      "z: -128.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.09114260206035539, -128.0)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_scale_zero_point(intermediate_output_float32, 256)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T21:38:53.103598Z",
     "end_time": "2023-04-07T21:38:53.161055Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# int8 quantization mnist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arr_w1 = model.layers[0].get_weights()[0]\n",
    "arr_b1 = model.layers[0].get_weights()[1]\n",
    "\n",
    "arr_w2 = model.layers[1].get_weights()[0]\n",
    "arr_b2 = model.layers[1].get_weights()[1]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "int8_s_w1, int_8s_z1, int8_w1 = weight_arr_quan(arr_w1, -127, 127)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# int4 quantization mnist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# int2 quantization mnist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
