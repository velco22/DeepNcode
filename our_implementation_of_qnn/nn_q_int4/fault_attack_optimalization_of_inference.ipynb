{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import hamming\n",
    "import tensorflow as tf\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import pathlib"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:20.924728Z",
     "end_time": "2023-04-24T15:26:28.787648Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def fault_attack(nn_arrays, n_faults):\n",
    "\n",
    "    output_arr = copy.deepcopy(nn_arrays)\n",
    "\n",
    "    size = 0\n",
    "    for arr in output_arr:\n",
    "        size += arr.size\n",
    "\n",
    "    if n_faults >= size:\n",
    "        output_arr *= -1\n",
    "\n",
    "    elif n_faults > 0:\n",
    "\n",
    "        index = 0\n",
    "        arr_n_faults = np.zeros(nn_arrays.shape[0], dtype=np.int64)\n",
    "\n",
    "        while n_faults != 0:\n",
    "\n",
    "            n_faults_arr = min(nn_arrays[index].size - arr_n_faults[index], n_faults)\n",
    "\n",
    "            if(n_faults_arr>0):\n",
    "                n_faults_arr = np.random.randint(0, n_faults_arr+1)\n",
    "                n_faults -= n_faults_arr\n",
    "                arr_n_faults[index] += n_faults_arr\n",
    "\n",
    "\n",
    "            index += 1\n",
    "            if index == nn_arrays.shape[0]:\n",
    "                index = 0\n",
    "\n",
    "        print(arr_n_faults)\n",
    "\n",
    "        for i in range(nn_arrays.shape[0]):\n",
    "\n",
    "            attack = np.random.permutation(nn_arrays[i].size)[:arr_n_faults[i]]\n",
    "\n",
    "            for j in attack:\n",
    "                neuron = int(j / nn_arrays[i].shape[1])\n",
    "                weight = j % nn_arrays[i].shape[1]\n",
    "                output_arr[i][neuron][weight] *= -1\n",
    "\n",
    "\n",
    "    return output_arr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:28.787648Z",
     "end_time": "2023-04-24T15:26:28.803390Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size: 28, input_size: 784\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (eva_images, eva_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images_float32_28x28 = train_images.astype(np.float32) / 255.0\n",
    "eva_images_float32_28x28 = eva_images.astype(np.float32) / 255.0\n",
    "\n",
    "# image dimensions (assumed square)\n",
    "image_size = train_images_float32_28x28.shape[1]\n",
    "input_size = image_size * image_size\n",
    "print(f'image_size: {image_size}, input_size: {input_size}')\n",
    "\n",
    "#reshape data to fit model\n",
    "train_images_float32 = np.reshape(train_images_float32_28x28, [-1, input_size])\n",
    "eva_images_float32 = np.reshape(eva_images_float32_28x28, [-1, input_size])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:28.803390Z",
     "end_time": "2023-04-24T15:26:29.070465Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(array([ 85, 126, 116, 107, 110,  87,  87,  99,  89,  94], dtype=int64),\n array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(eva_labels[:1000], bins='auto')\n",
    "plt.show()\n",
    "\n",
    "np.histogram(eva_labels[:1000])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:29.070465Z",
     "end_time": "2023-04-24T15:26:29.180138Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7 -7 -7 -5 -7  5 -2 -1 -7  5  2  3  5  5  6  5 -7 -7  2 -1 -4 -1 -1 -1\n",
      "  2  1  2  2  4  5  2 -1 -7 -5 -5 -5 -4 -3  6 -5  0  1  6 -5  6  5  6  6\n",
      " -4  1 -6 -5 -4 -4 -4 -1  1  1  2  1 -4  1  6  7 -7 -7 -2  3 -2 -3 -2 -2\n",
      "  0  3  3  3  4  5 -2  3 -7 -7 -6 -7  4 -7 -2 -1  4 -7  2  3  4  4  4  7\n",
      "  0 -3 -6 -5 -3 -3 -2 -3  0  0  0  3  0 -3  6  7 -6 -7 -6 -6 -4 -3 -6  7\n",
      "  0  1 -6  7  4  7  7  7]\n"
     ]
    }
   ],
   "source": [
    "error_correction = np.load(\"table_error_correction_2bit.npy\")\n",
    "print(error_correction)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:29.180138Z",
     "end_time": "2023-04-24T15:26:29.187956Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  81 114  35  52 101  70  23 104  57  26  75  92  13  46 127]\n"
     ]
    }
   ],
   "source": [
    "table_code_words = np.load(\"table_code_words.npy\")\n",
    "print(table_code_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:29.187956Z",
     "end_time": "2023-04-24T15:26:29.266213Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self.modules = OrderedDict()\n",
    "\n",
    "    def add_module(self, module, name: str):\n",
    "        self.modules[name] = module\n",
    "\n",
    "    def forward(self, input) -> np.ndarray:\n",
    "        for module in self.modules:\n",
    "            # print(f\"module: {module}\")\n",
    "            input = self.modules[module].forward(input)\n",
    "\n",
    "        return input\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   FullyConnected class\n",
    "#------------------------------------------------------------------------------\n",
    "class FullyConnected(Module):\n",
    "    def __init__(self, w, b, s_w, s_i, s_o, z_i, z_o, min_T, max_T):\n",
    "        super(FullyConnected, self).__init__()\n",
    "        self.W = w\n",
    "        self.b = b\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.m = s_i * s_w / s_o\n",
    "        self.s_b = s_i * s_w\n",
    "        self.min_T = min_T\n",
    "        self.max_T = max_T\n",
    "        print(self.W.shape)\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        output_int8 = np.zeros((input.shape[0], self.W.shape[1]), dtype=np.int8)\n",
    "        output = np.zeros((input.shape[0], self.W.shape[1]), dtype=np.int32)\n",
    "        a2 = np.zeros((self.W.shape[1]), dtype=np.int32)\n",
    "\n",
    "        for i in range(input.shape[0]):\n",
    "            for k in range(self.W.shape[1]):\n",
    "                for j in range(input.shape[1]):\n",
    "                    a2[k] += np.int32(self.W[j][k])\n",
    "                    output[i][k] += np.int32(input[i][j]) * np.int32(self.W[j][k])\n",
    "\n",
    "                    # print(f'i = {input[i][j]}, W = {self.W[j][k]}, output_32 = {output[i][k]}, a2={a2[k]}')\n",
    "\n",
    "                # print('-----------------')\n",
    "                # print(f'z_o = {self.z_o}, m = {self.m}, o = {output[i][k]}, b = {self.b[k]}, a2 = {a2[k]}, z_i = {self.z_i}, zia2: {-self.z_i*a2[k]}')\n",
    "                # print(f'output_before_saturate_cast = ',np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k]))\n",
    "\n",
    "                # output_int8[i][k] = tf.dtypes.saturate_cast(np.round(np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k])), tf.int8)\n",
    "\n",
    "                output_value = np.round(\n",
    "                    np.int32(self.z_o) + self.m * (-(np.int32(self.z_i) * a2[k]) + output[i][k] + self.b[k]), 0)\n",
    "\n",
    "                if output_value > self.max_T:\n",
    "                    output_int8[i][k] = np.int8(self.max_T)\n",
    "                elif output_value < self.min_T:\n",
    "                    output_int8[i][k] = np.int8(self.min_T)\n",
    "                else:\n",
    "                    output_int8[i][k] = np.int8(output_value)\n",
    "\n",
    "                # print('output_int8: ', output_int8[i][k])\n",
    "                # print('-----------------')\n",
    "\n",
    "        # print(f'input: {input} \\noutput: {output_int8}\\n-----------------\\n-----------------')\n",
    "        # print(f'input: {input.dtype} \\noutput2: {output_int8.dtype}\\n-----------------')\n",
    "\n",
    "        return output_int8\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   FullyConnected_fullprotection class\n",
    "#------------------------------------------------------------------------------\n",
    "class FullyConnected_fullprotection(Module):\n",
    "    def __init__(self, w_encoded, b, s_w, s_i, s_o, z_i, z_o, min_T, max_T):\n",
    "        super(FullyConnected_fullprotection, self).__init__()\n",
    "        self.W_encoded = w_encoded\n",
    "        self.b = b\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.m = s_i * s_w / s_o\n",
    "        self.s_b = s_i * s_w\n",
    "        self.min_T = min_T\n",
    "        self.max_T = max_T\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        output_int8 = np.zeros((input.shape[0], self.W_encoded.shape[1]), dtype=np.int8)\n",
    "        output = np.zeros((input.shape[0], self.W_encoded.shape[1]), dtype=np.int32)\n",
    "        a2 = np.zeros((self.W_encoded.shape[1]), dtype=np.int32)\n",
    "\n",
    "        for i in range(input.shape[0]):\n",
    "            for k in range(self.W_encoded.shape[1]):\n",
    "                for j in range(input.shape[1]):\n",
    "                    a2[k] += np.int32(error_correction[self.W_encoded[j][k]])\n",
    "                    output[i][k] += np.int32(input[i][j]) * np.int32(error_correction[self.W_encoded[j][k]])\n",
    "\n",
    "                    # try:\n",
    "                    #     output[i][k] += np.int32(table_lookup_multiplication[input[i][j]][self.W_encoded[j][k]])\n",
    "                    # except:\n",
    "                    #     try:\n",
    "                    #         output[i][k] += np.int32(table_lookup_multiplication[self.W_encoded[j][k]][input[i][j]])\n",
    "                    #     except:\n",
    "                    #         print(\"except: error\")\n",
    "\n",
    "                    # print(f'i = {input[i][j]}, W = {self.W[j][k]}, output_32 = {output[i][k]}, a2={a2[k]}')\n",
    "\n",
    "                # print('-----------------')\n",
    "                # print(f'z_o = {self.z_o}, m = {self.m}, o = {output[i][k]}, b = {self.b[k]}, a2 = {a2[k]}, z_i = {self.z_i}, zia2: {-self.z_i*a2[k]}')\n",
    "                # print(f'output_before_saturate_cast = ',np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k]))\n",
    "\n",
    "                # output_int8[i][k] = tf.dtypes.saturate_cast(np.round(np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k])), tf.int8)\n",
    "\n",
    "                output_value = np.round(\n",
    "                    np.int32(self.z_o) + self.m * (-(np.int32(self.z_i) * a2[k]) + output[i][k] + self.b[k]), 0)\n",
    "\n",
    "                if output_value > self.max_T:\n",
    "                    output_int8[i][k] = np.int8(self.max_T)\n",
    "                elif output_value < self.min_T:\n",
    "                    output_int8[i][k] = np.int8(self.min_T)\n",
    "                else:\n",
    "                    output_int8[i][k] = np.int8(output_value)\n",
    "\n",
    "                # print('output_int8: ', output_int8[i][k])\n",
    "                # print('-----------------')\n",
    "\n",
    "        # print(f'input: {input} \\noutput: {output_int8}\\n-----------------\\n-----------------')\n",
    "        # print(f'input: {input.dtype} \\noutput2: {output_int8.dtype}\\n-----------------')\n",
    "\n",
    "        return output_int8\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   FullyConnected_encoded class\n",
    "#------------------------------------------------------------------------------\n",
    "class FullyConnected_encoded(Module):\n",
    "    def __init__(self, w, w_encoded, b, s_w, s_i, s_o, z_i, z_o, min_T, max_T):\n",
    "        super(FullyConnected_encoded, self).__init__()\n",
    "        self.W = w\n",
    "        self.W_encoded = w_encoded\n",
    "        self.b = b\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.m = s_i * s_w / s_o\n",
    "        self.s_b = s_i * s_w\n",
    "        self.min_T = min_T\n",
    "        self.max_T = max_T\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        output_int8 = np.zeros((input.shape[0], self.W.shape[1]), dtype=np.int8)\n",
    "        output = np.zeros((input.shape[0], self.W.shape[1]), dtype=np.int32)\n",
    "        a2 = np.zeros((self.W.shape[1]), dtype=np.int32)\n",
    "\n",
    "        for i in range(input.shape[0]):\n",
    "            for k in range(self.W.shape[1]):\n",
    "                for j in range(input.shape[1]):\n",
    "                    a2[k] += np.int32(self.W[j][k])\n",
    "                    # output[i][k] += np.int32(input[i][j]) * np.int32(self.W[j][k])\n",
    "                    output[i][k] += np.int32(input[i][j]) * np.int32(error_correction[self.W_encoded[j][k]])\n",
    "                    # output[i][k] += np.int32(table_lookup_multiplication_full[input[i][j]][self.W_encoded[j][k]])\n",
    "                    # try:\n",
    "                    #     output[i][k] += np.int32(error_correction[self.W_encoded[j][k]])\n",
    "                    # except:\n",
    "                    #     try:\n",
    "                    #         output[i][k] += np.int32(error_correction[self.W_encoded[j][k]])\n",
    "                    #     except:\n",
    "                    #         print(\"except: error\")\n",
    "\n",
    "                    # print(f'i = {input[i][j]}, W = {self.W[j][k]}, output_32 = {output[i][k]}, a2={a2[k]}')\n",
    "\n",
    "                # print('-----------------')\n",
    "                # print(f'z_o = {self.z_o}, m = {self.m}, o = {output[i][k]}, b = {self.b[k]}, a2 = {a2[k]}, z_i = {self.z_i}, zia2: {-self.z_i*a2[k]}')\n",
    "                # print(f'output_before_saturate_cast = ',np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k]))\n",
    "\n",
    "                # output_int8[i][k] = tf.dtypes.saturate_cast(np.round(np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k])), tf.int8)\n",
    "\n",
    "                output_value = np.round(\n",
    "                    np.int32(self.z_o) + self.m * (-(np.int32(self.z_i) * a2[k]) + output[i][k] + self.b[k]), 0)\n",
    "\n",
    "                if output_value > self.max_T:\n",
    "                    output_int8[i][k] = np.int8(self.max_T)\n",
    "                elif output_value < self.min_T:\n",
    "                    output_int8[i][k] = np.int8(self.min_T)\n",
    "                else:\n",
    "                    output_int8[i][k] = np.int8(output_value)\n",
    "\n",
    "                # print('output_int8: ', output_int8[i][k])\n",
    "                # print('-----------------')\n",
    "\n",
    "        # print(f'input: {input} \\noutput: {output_int8}\\n-----------------\\n-----------------')\n",
    "        # print(f'input: {input.dtype} \\noutput2: {output_int8.dtype}\\n-----------------')\n",
    "\n",
    "        return output_int8\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   Quantize class\n",
    "#------------------------------------------------------------------------------\n",
    "class Quantize(Module):\n",
    "    def __init__(self, s, z_i, z_o, d_type):\n",
    "        super(Quantize, self).__init__()\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.s = s\n",
    "        self.d_type = d_type\n",
    "\n",
    "        # print(f'Quantize: z_i: {self.z_i} z_o: {self.z_o} s: {self.s} d_type: {self.d_type}')\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        # converts from int8 to uint8 and vice versa\n",
    "        if self.d_type is np.int8:\n",
    "            arr_q = (input + 128).astype(np.uint8)\n",
    "        elif self.d_type is np.uint8:\n",
    "            arr_q = (input - 128).astype(np.int8)\n",
    "        else:\n",
    "            raise ValueError(f'input type is not supported: {input.dtype}')\n",
    "\n",
    "        # print(f'input: {input} \\noutput: {arr_q}\\n-----------------\\n-----------------')\n",
    "        # print(f'input: {input.dtype} \\noutput: {arr_q.dtype}\\n-----------------')\n",
    "\n",
    "        return arr_q"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:29.219335Z",
     "end_time": "2023-04-24T15:26:29.281846Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fastest way to calculate the dot product of two matrices in Python \n",
    "## f1 is fastest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self.modules = OrderedDict()\n",
    "\n",
    "    def add_module(self, module, name: str):\n",
    "        self.modules[name] = module\n",
    "\n",
    "    def forward(self, input) -> np.ndarray:\n",
    "        for module in self.modules:\n",
    "            # print(f\"module: {module}\")\n",
    "            input = self.modules[module].forward(input)\n",
    "\n",
    "        return input\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   FullyConnected class\n",
    "#------------------------------------------------------------------------------\n",
    "class FullyConnected_f1(Module):\n",
    "    def __init__(self, w, b, s_w, s_i, s_o, z_i, z_o, min_T, max_T):\n",
    "        super(FullyConnected_f1, self).__init__()\n",
    "        self.W = w.T\n",
    "        self.b = b.T\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.m = s_i * s_w / s_o\n",
    "        self.min_T = min_T\n",
    "        self.max_T = max_T\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        output = np.matmul(np.int32(input), np.int32(self.W))\n",
    "        a2 = np.sum(np.int32(self.W), axis=0)\n",
    "\n",
    "        output_values = np.int32(self.z_o) + self.m * (-(np.int32(self.z_i) * a2) + output + self.b)\n",
    "\n",
    "        output_values = np.where(output_values > self.max_T, self.max_T, output_values)\n",
    "        output_values = np.where(output_values < self.min_T, self.min_T, output_values)\n",
    "\n",
    "        return np.int8(np.round(output_values))\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   FullyConnected_fullprotection class\n",
    "#------------------------------------------------------------------------------\n",
    "class FullyConnected_fullprotection_f1(Module):\n",
    "    def __init__(self, w_encoded, b, s_w, s_i, s_o, z_i, z_o, min_T, max_T):\n",
    "        super(FullyConnected_fullprotection_f1, self).__init__()\n",
    "        self.W_encoded = w_encoded.T\n",
    "        self.b = b.T\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.m = s_i * s_w / s_o\n",
    "        self.min_T = min_T\n",
    "        self.max_T = max_T\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        W_decoded = np.vectorize(error_correction.__getitem__)(self.W_encoded)\n",
    "        output = np.matmul(np.int32(input), np.int32(W_decoded))\n",
    "        a2 = np.sum(np.int32(W_decoded), axis=0)\n",
    "\n",
    "        output_values = np.int32(self.z_o) + self.m * (-(np.int32(self.z_i) * a2) + output + self.b)\n",
    "\n",
    "        output_values = np.where(output_values > self.max_T, self.max_T, output_values)\n",
    "        output_values = np.where(output_values < self.min_T, self.min_T, output_values)\n",
    "\n",
    "        return np.int8(np.round(output_values))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:29.234889Z",
     "end_time": "2023-04-24T15:26:29.281846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#   FullyConnected class\n",
    "#------------------------------------------------------------------------------\n",
    "class FullyConnected_f2(Module):\n",
    "    def __init__(self, w, b, s_w, s_i, s_o, z_i, z_o, min_T, max_T):\n",
    "        super(FullyConnected_f2, self).__init__()\n",
    "        self.W = w\n",
    "        self.b = b\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.m = s_i * s_w / s_o\n",
    "        self.s_b = s_i * s_w\n",
    "        self.min_T = min_T\n",
    "        self.max_T = max_T\n",
    "        print(self.W.shape)\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        output_int8 = np.zeros((input.shape[0], self.W.shape[1]), dtype=np.int8)\n",
    "        # print(input.shape, self.W.shape)\n",
    "        output = np.matmul(np.int32(input), np.int32(self.W))\n",
    "\n",
    "        for i in range(input.shape[0]):\n",
    "            for k in range(self.W.shape[1]):\n",
    "                a2 = np.sum(self.W[:, k])\n",
    "                # for j in range(input.shape[1]):\n",
    "                    # a2[k] += np.int32(self.W[j][k])\n",
    "                    # output[i][k] += np.int32(input[i][j]) * np.int32(self.W[j][k])\n",
    "\n",
    "                    # print(f'i = {input[i][j]}, W = {self.W[j][k]}, output_32 = {output[i][k]}, a2={a2[k]}')\n",
    "\n",
    "                # print('-----------------')\n",
    "                # print(f'z_o = {self.z_o}, m = {self.m}, o = {output[i][k]}, b = {self.b[k]}, a2 = {a2[k]}, z_i = {self.z_i}, zia2: {-self.z_i*a2[k]}')\n",
    "                # print(f'output_before_saturate_cast = ',np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k]))\n",
    "\n",
    "                # output_int8[i][k] = tf.dtypes.saturate_cast(np.round(np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k])), tf.int8)\n",
    "\n",
    "                output_value = np.round(np.int32(self.z_o) + self.m * (-(np.int32(self.z_i) * a2) + output[i][k] + self.b[k]), 0)\n",
    "\n",
    "                if output_value > self.max_T:\n",
    "                    output_int8[i][k] = np.int8(self.max_T)\n",
    "                elif output_value < self.min_T:\n",
    "                    output_int8[i][k] = np.int8(self.min_T)\n",
    "                else:\n",
    "                    output_int8[i][k] = np.int8(output_value)\n",
    "\n",
    "                # print('output_int8: ', output_int8[i][k])\n",
    "                # print('-----------------')\n",
    "\n",
    "        # print(f'input: {input} \\noutput: {output_int8}\\n-----------------\\n-----------------')\n",
    "        # print(f'input: {input.dtype} \\noutput2: {output_int8.dtype}\\n-----------------')\n",
    "\n",
    "        return output_int8\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   FullyConnected_fullprotection class\n",
    "#------------------------------------------------------------------------------\n",
    "error_correction_vec = np.vectorize(lambda x: error_correction[x])\n",
    "\n",
    "class FullyConnected_fullprotection_f2(Module):\n",
    "    def __init__(self, w_encoded, b, s_w, s_i, s_o, z_i, z_o, min_T, max_T):\n",
    "        super(FullyConnected_fullprotection_f2, self).__init__()\n",
    "        self.W_encoded = w_encoded\n",
    "        self.b = b\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.m = s_i * s_w / s_o\n",
    "        self.s_b = s_i * s_w\n",
    "        self.min_T = min_T\n",
    "        self.max_T = max_T\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        output_int8 = np.zeros((input.shape[0], self.W_encoded.shape[1]), dtype=np.int8)\n",
    "        # W_decoded = np.zeros(self.W_encoded.shape, dtype=np.int8)\n",
    "\n",
    "\n",
    "        # error_correction_vec = np.vectorize(lambda x: error_correction[x])\n",
    "        W_decoded = error_correction_vec(self.W_encoded)\n",
    "\n",
    "        # for i in range(self.W_encoded.shape[0]):\n",
    "        #     for j in range(self.W_encoded.shape[1]):\n",
    "        #         W_decoded[i][j] = error_correction[self.W_encoded[i][j]]\n",
    "\n",
    "        output = np.matmul(np.int32(input), np.int32(W_decoded))\n",
    "\n",
    "\n",
    "        for i in range(input.shape[0]):\n",
    "            for k in range(self.W_encoded.shape[1]):\n",
    "                a2 = np.sum(np.int32(W_decoded[:, k]))\n",
    "\n",
    "                    # try:\n",
    "                    #     output[i][k] += np.int32(table_lookup_multiplication[input[i][j]][self.W_encoded[j][k]])\n",
    "                    # except:\n",
    "                    #     try:\n",
    "                    #         output[i][k] += np.int32(table_lookup_multiplication[self.W_encoded[j][k]][input[i][j]])\n",
    "                    #     except:\n",
    "                    #         print(\"except: error\")\n",
    "\n",
    "                    # print(f'i = {input[i][j]}, W = {self.W[j][k]}, output_32 = {output[i][k]}, a2={a2[k]}')\n",
    "\n",
    "                # print('-----------------')\n",
    "                # print(f'z_o = {self.z_o}, m = {self.m}, o = {output[i][k]}, b = {self.b[k]}, a2 = {a2[k]}, z_i = {self.z_i}, zia2: {-self.z_i*a2[k]}')\n",
    "                # print(f'output_before_saturate_cast = ',np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k]))\n",
    "\n",
    "                # output_int8[i][k] = tf.dtypes.saturate_cast(np.round(np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k])), tf.int8)\n",
    "\n",
    "                output_value = np.round(\n",
    "                    np.int32(self.z_o) + self.m * (-(np.int32(self.z_i) * a2) + output[i][k] + self.b[k]), 0)\n",
    "\n",
    "                if output_value > self.max_T:\n",
    "                    output_int8[i][k] = np.int8(self.max_T)\n",
    "                elif output_value < self.min_T:\n",
    "                    output_int8[i][k] = np.int8(self.min_T)\n",
    "                else:\n",
    "                    output_int8[i][k] = np.int8(output_value)\n",
    "\n",
    "                # print('output_int8: ', output_int8[i][k])\n",
    "                # print('-----------------')\n",
    "\n",
    "        # print(f'input: {input} \\noutput: {output_int8}\\n-----------------\\n-----------------')\n",
    "        # print(f'input: {input.dtype} \\noutput2: {output_int8.dtype}\\n-----------------')\n",
    "\n",
    "        return output_int8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:29.250458Z",
     "end_time": "2023-04-24T15:26:29.281846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#   FullyConnected class\n",
    "#------------------------------------------------------------------------------\n",
    "class FullyConnected_f3(Module):\n",
    "    def __init__(self, w, b, s_w, s_i, s_o, z_i, z_o, min_T, max_T):\n",
    "        super(FullyConnected_f3, self).__init__()\n",
    "        self.W = w\n",
    "        self.b = b\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.m = s_i * s_w / s_o\n",
    "        self.s_b = s_i * s_w\n",
    "        self.min_T = min_T\n",
    "        self.max_T = max_T\n",
    "        print(self.W.shape)\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        output_int8 = np.zeros((input.shape[0], self.W.shape[0]), dtype=np.int8)\n",
    "\n",
    "        for k in range(self.W.shape[0]):\n",
    "            a2 = np.sum(self.W[k])\n",
    "            for i in range(input.shape[0]):\n",
    "                output = np.sum(np.int32(input[i]) * np.int32(self.W[k]))\n",
    "                # for j in range(input.shape[1]):\n",
    "                    # a2[k] += np.int32(self.W[j][k])\n",
    "                    # output[i][k] += np.int32(input[i][j]) * np.int32(self.W[j][k])\n",
    "\n",
    "                    # print(f'i = {input[i][j]}, W = {self.W[j][k]}, output_32 = {output[i][k]}, a2={a2[k]}')\n",
    "\n",
    "                # print('-----------------')\n",
    "                # print(f'z_o = {self.z_o}, m = {self.m}, o = {output[i][k]}, b = {self.b[k]}, a2 = {a2[k]}, z_i = {self.z_i}, zia2: {-self.z_i*a2[k]}')\n",
    "                # print(f'output_before_saturate_cast = ',np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k]))\n",
    "\n",
    "                # output_int8[i][k] = tf.dtypes.saturate_cast(np.round(np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k])), tf.int8)\n",
    "\n",
    "                output_value = np.round(np.int32(self.z_o) + self.m * (-(np.int32(self.z_i) * a2) + output + self.b[k]), 0)\n",
    "\n",
    "                if output_value > self.max_T:\n",
    "                    output_int8[i][k] = np.int8(self.max_T)\n",
    "                elif output_value < self.min_T:\n",
    "                    output_int8[i][k] = np.int8(self.min_T)\n",
    "                else:\n",
    "                    output_int8[i][k] = np.int8(output_value)\n",
    "\n",
    "                # print('output_int8: ', output_int8[i][k])\n",
    "                # print('-----------------')\n",
    "\n",
    "        # print(f'input: {input} \\noutput: {output_int8}\\n-----------------\\n-----------------')\n",
    "        # print(f'input: {input.dtype} \\noutput2: {output_int8.dtype}\\n-----------------')\n",
    "\n",
    "        return output_int8\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   FullyConnected_fullprotection class\n",
    "#------------------------------------------------------------------------------\n",
    "error_correction_vec = np.vectorize(lambda x: error_correction[x])\n",
    "\n",
    "class FullyConnected_fullprotection_f3(Module):\n",
    "    def __init__(self, w_encoded, b, s_w, s_i, s_o, z_i, z_o, min_T, max_T):\n",
    "        super(FullyConnected_fullprotection_f3, self).__init__()\n",
    "        self.W_encoded = w_encoded\n",
    "        self.b = b\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.m = s_i * s_w / s_o\n",
    "        self.s_b = s_i * s_w\n",
    "        self.min_T = min_T\n",
    "        self.max_T = max_T\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        W_decoded = error_correction_vec(self.W_encoded)\n",
    "\n",
    "        output = np.matmul(np.int32(input), np.int32(W_decoded))\n",
    "\n",
    "        a2 = np.sum(np.int32(W_decoded), axis=0)\n",
    "\n",
    "        output_values = np.int32(self.z_o) + self.m * (-(np.int32(self.z_i) * a2) + output + self.b.reshape(1, -1))\n",
    "\n",
    "        output_values = np.where(output_values > self.max_T, self.max_T, output_values)\n",
    "        output_values = np.where(output_values < self.min_T, self.min_T, output_values)\n",
    "\n",
    "        output_int8 = np.int8(np.round(output_values))\n",
    "\n",
    "        return output_int8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:29.266213Z",
     "end_time": "2023-04-24T15:26:29.281846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#   FullyConnected class\n",
    "#------------------------------------------------------------------------------\n",
    "class FullyConnected_f4(Module):\n",
    "    def __init__(self, w, b, s_w, s_i, s_o, z_i, z_o, min_T, max_T):\n",
    "        super(FullyConnected_f4, self).__init__()\n",
    "        self.W = w\n",
    "        self.b = b\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.m = s_i * s_w / s_o\n",
    "        self.s_b = s_i * s_w\n",
    "        self.min_T = min_T\n",
    "        self.max_T = max_T\n",
    "        print(self.W.shape)\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        output_int8 = np.zeros((input.shape[0], self.W.shape[1]), dtype=np.int8)\n",
    "        output = np.matmul(np.int32(input), np.int32(self.W))\n",
    "\n",
    "        for k in range(self.W.shape[1]):\n",
    "            a2 = np.sum(self.W[:, k])\n",
    "            for i in range(input.shape[0]):\n",
    "                # output = np.sum(np.int32(input[i]) * np.int32(self.W[k]))\n",
    "                # for j in range(input.shape[1]):\n",
    "                    # a2[k] += np.int32(self.W[j][k])\n",
    "                    # output[i][k] += np.int32(input[i][j]) * np.int32(self.W[j][k])\n",
    "\n",
    "                    # print(f'i = {input[i][j]}, W = {self.W[j][k]}, output_32 = {output[i][k]}, a2={a2[k]}')\n",
    "\n",
    "                # print('-----------------')\n",
    "                # print(f'z_o = {self.z_o}, m = {self.m}, o = {output[i][k]}, b = {self.b[k]}, a2 = {a2[k]}, z_i = {self.z_i}, zia2: {-self.z_i*a2[k]}')\n",
    "                # print(f'output_before_saturate_cast = ',np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k]))\n",
    "\n",
    "                # output_int8[i][k] = tf.dtypes.saturate_cast(np.round(np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k])), tf.int8)\n",
    "\n",
    "                output_value = np.round(np.int32(self.z_o) + self.m * (-(np.int32(self.z_i) * a2) + output[i][k] + self.b[k]), 0)\n",
    "\n",
    "                if output_value > self.max_T:\n",
    "                    output_int8[i][k] = np.int8(self.max_T)\n",
    "                elif output_value < self.min_T:\n",
    "                    output_int8[i][k] = np.int8(self.min_T)\n",
    "                else:\n",
    "                    output_int8[i][k] = np.int8(output_value)\n",
    "\n",
    "                # print('output_int8: ', output_int8[i][k])\n",
    "                # print('-----------------')\n",
    "\n",
    "        # print(f'input: {input} \\noutput: {output_int8}\\n-----------------\\n-----------------')\n",
    "        # print(f'input: {input.dtype} \\noutput2: {output_int8.dtype}\\n-----------------')\n",
    "\n",
    "        return output_int8\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   FullyConnected_fullprotection class\n",
    "#------------------------------------------------------------------------------\n",
    "error_correction_vec = np.vectorize(lambda x: error_correction[x])\n",
    "\n",
    "class FullyConnected_fullprotection_f4(Module):\n",
    "    def __init__(self, w_encoded, b, s_w, s_i, s_o, z_i, z_o, min_T, max_T):\n",
    "        super(FullyConnected_fullprotection_f4, self).__init__()\n",
    "        self.W_encoded = w_encoded\n",
    "        self.b = b\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.m = s_i * s_w / s_o\n",
    "        self.s_b = s_i * s_w\n",
    "        self.min_T = min_T\n",
    "        self.max_T = max_T\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        output_int8 = np.zeros((input.shape[0], self.W_encoded.shape[1]), dtype=np.int8)\n",
    "        # W_decoded = np.zeros(self.W_encoded.shape, dtype=np.int8)\n",
    "\n",
    "        # for i in range(self.W_encoded.shape[0]):\n",
    "        #     for j in range(self.W_encoded.shape[1]):\n",
    "        #         W_decoded[i][j] = error_correction[self.W_encoded[i][j]]\n",
    "\n",
    "        W_decoded = error_correction_vec(self.W_encoded)\n",
    "\n",
    "        output = np.matmul(np.int32(input), np.int32(W_decoded))\n",
    "\n",
    "        for k in range(self.W_encoded.shape[1]):\n",
    "            a2 = np.sum(np.int32(W_decoded[:, k]))\n",
    "\n",
    "            for i in range(input.shape[0]):\n",
    "\n",
    "                    # try:\n",
    "                    #     output[i][k] += np.int32(table_lookup_multiplication[input[i][j]][self.W_encoded[j][k]])\n",
    "                    # except:\n",
    "                    #     try:\n",
    "                    #         output[i][k] += np.int32(table_lookup_multiplication[self.W_encoded[j][k]][input[i][j]])\n",
    "                    #     except:\n",
    "                    #         print(\"except: error\")\n",
    "\n",
    "                    # print(f'i = {input[i][j]}, W = {self.W[j][k]}, output_32 = {output[i][k]}, a2={a2[k]}')\n",
    "\n",
    "                # print('-----------------')\n",
    "                # print(f'z_o = {self.z_o}, m = {self.m}, o = {output[i][k]}, b = {self.b[k]}, a2 = {a2[k]}, z_i = {self.z_i}, zia2: {-self.z_i*a2[k]}')\n",
    "                # print(f'output_before_saturate_cast = ',np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k]))\n",
    "\n",
    "                # output_int8[i][k] = tf.dtypes.saturate_cast(np.round(np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k])), tf.int8)\n",
    "\n",
    "                output_value = np.round(\n",
    "                    np.int32(self.z_o) + self.m * (-(np.int32(self.z_i) * a2) + output[i][k] + self.b[k]), 0)\n",
    "\n",
    "                if output_value > self.max_T:\n",
    "                    output_int8[i][k] = np.int8(self.max_T)\n",
    "                elif output_value < self.min_T:\n",
    "                    output_int8[i][k] = np.int8(self.min_T)\n",
    "                else:\n",
    "                    output_int8[i][k] = np.int8(output_value)\n",
    "\n",
    "                # print('output_int8: ', output_int8[i][k])\n",
    "                # print('-----------------')\n",
    "\n",
    "        # print(f'input: {input} \\noutput: {output_int8}\\n-----------------\\n-----------------')\n",
    "        # print(f'input: {input.dtype} \\noutput2: {output_int8.dtype}\\n-----------------')\n",
    "\n",
    "        return output_int8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:29.281846Z",
     "end_time": "2023-04-24T15:26:29.313650Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Weight quantization\n",
    "# https://www.tensorflow.org/api_docs/python/tf/quantization/quantize\n",
    "def weight_scaling_factor(a, b, min_T, max_T):\n",
    "    s_a = a / min_T\n",
    "    s_b = b / max_T\n",
    "\n",
    "    if s_a > s_b:\n",
    "        return s_a, a, max_T * s_a\n",
    "    else:\n",
    "        return s_b, min_T * s_b, b\n",
    "\n",
    "def clamp(r,a,b):\n",
    "    return min(max(r, a), b)\n",
    "\n",
    "clamp_vec = np.vectorize(clamp)\n",
    "\n",
    "def weight_quan(r, a, b, min_T, s):\n",
    "\n",
    "    q_value = np.round((clamp(r,a,b) - a) / s) + min_T\n",
    "\n",
    "    # print(f'q_value: {q_value}')\n",
    "    # print(f'q_value_2: {np.round((clamp(r,a,b)) / s)}')\n",
    "    # print(f'q_value_3: {np.int8(np.round((clamp(r,a,b)) / s))}')\n",
    "\n",
    "    # z = 0\n",
    "    # r = s * (q_value - z)\n",
    "\n",
    "    # print(f'r: {r}')\n",
    "\n",
    "    return q_value\n",
    "\n",
    "def weight_arr_quan(input_arr, min_T, max_T):\n",
    "\n",
    "    a, b = np.min(input_arr), np.max(input_arr)\n",
    "    s, a, b = weight_scaling_factor(a, b, min_T, max_T)\n",
    "\n",
    "    # out_arr = np.zeros(input_arr.shape, dtype=np.int8).T\n",
    "    #\n",
    "    # for i in range(input_arr.shape[0]):\n",
    "    #     for j in range(input_arr.shape[1]):\n",
    "    #         out_arr[j][i] = weight_quan(input_arr[i][j], a, b, min_T, s)\n",
    "\n",
    "    out_arr = np.int8(np.round(((clamp_vec(input_arr, a, b) - a) / s) + min_T)).T\n",
    "\n",
    "    return s, 0, out_arr\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Activation quantization\n",
    "\n",
    "def activation_scaling_factor(a, b, n):\n",
    "   return (b - a) / (n - 1)\n",
    "\n",
    "def activation_scale_zero_point(input_array, n):\n",
    "    a, b = np.min(input_array), np.max(input_array)\n",
    "    s = (b - a) / (n - 1)\n",
    "    q_value = np.round((0 - a) / s) - n/2 #zero point\n",
    "\n",
    "    return s, q_value\n",
    "\n",
    "def activation_quan(r, a, b, n, s, z):\n",
    "\n",
    "    q_value = np.round((clamp(r,a,b) - a) / s) - n/2\n",
    "\n",
    "    # print(f'q_value: {q_value}')\n",
    "\n",
    "    # r = s * (q_value - z)\n",
    "    # print(f'r: {r}')\n",
    "\n",
    "    return q_value\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Bias quantization\n",
    "\n",
    "def bias_quan(r, s_w, s_i):\n",
    "    return np.round(r / (s_i * s_w))\n",
    "\n",
    "def bias_arr_quan(arr, s_w, s_i):\n",
    "\n",
    "    # arr = np.array([bias_quan(r, s_w, s_i) for r in arr], dtype=np.int32)\n",
    "    # s = s_w * s_i\n",
    "\n",
    "    s = s_w * s_i\n",
    "    out_arr = np.int32(np.round(arr / s))\n",
    "\n",
    "    return s, 0, out_arr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:29.297885Z",
     "end_time": "2023-04-24T15:26:29.313650Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NN 200-200-200-10 architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(200, activation='relu', input_dim=input_size),\n",
    "        tf.keras.layers.Dense(200, activation='relu'),\n",
    "        tf.keras.layers.Dense(200, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "# model.fit(\n",
    "#     train_images_float32,\n",
    "#     train_labels,\n",
    "#     epochs=10,\n",
    "#     batch_size=64,\n",
    "#     validation_data=(eva_images_float32, eva_labels)\n",
    "# )\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"models\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "float_weights_path = r\"./models/mnist_float_nn_tf_layers4_neurons_200-200-200-10/mnist_float_weights\"\n",
    "\n",
    "# Save the model:\n",
    "float_weights_model_file = tflite_models_dir / \"mnist_float_nn_tf_layers4_neurons_200-200-200-10/mnist_float_weights\"\n",
    "float_weights_model_file_index = tflite_models_dir / \"mnist_float_nn_tf_layers4_neurons_200-200-200-10/mnist_float_weights.index\"\n",
    "if not float_weights_model_file_index.is_file():\n",
    "    model.save_weights(float_weights_model_file)\n",
    "    print(\"Float weights saved to: \", float_weights_model_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:29.313650Z",
     "end_time": "2023-04-24T15:26:29.422946Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x201451ee908>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.load_weights(float_weights_model_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:29.422946Z",
     "end_time": "2023-04-24T15:26:29.501027Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 2s 788us/step\n",
      "1875/1875 [==============================] - 2s 853us/step\n",
      "1875/1875 [==============================] - 2s 925us/step\n",
      "1875/1875 [==============================] - 2s 838us/step\n"
     ]
    }
   ],
   "source": [
    "# Define a new model that outputs the intermediate layer\n",
    "intermediate_model_1 = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
    "intermediate_model_2 = tf.keras.Model(inputs=model.input, outputs=model.layers[1].output)\n",
    "intermediate_model_3 = tf.keras.Model(inputs=model.input, outputs=model.layers[2].output)\n",
    "\n",
    "# Get the intermediate output for the entire input dataset\n",
    "intermediate_output_1_float32 = intermediate_model_1.predict(train_images_float32)\n",
    "intermediate_output_2_float32 = intermediate_model_2.predict(train_images_float32)\n",
    "intermediate_output_3_float32 = intermediate_model_3.predict(train_images_float32)\n",
    "\n",
    "outputs_float32 = model.predict(train_images_float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:29.501027Z",
     "end_time": "2023-04-24T15:26:37.218101Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 200)\n",
      "(200, 200)\n",
      "(200, 200)\n",
      "(200, 10)\n"
     ]
    }
   ],
   "source": [
    "int4_s_w1, int4_z_w1, int4_w1 = weight_arr_quan(model.layers[0].get_weights()[0], -7, 7)\n",
    "int4_s_i1, int4_z_i1 = activation_scale_zero_point(train_images_float32, 16)\n",
    "int4_s_b1, int4_z_b1, int4_b1 = bias_arr_quan(model.layers[0].get_weights()[1], int4_s_w1, int4_s_i1)\n",
    "\n",
    "int4_s_w2, int4_z_w2, int4_w2 = weight_arr_quan(model.layers[1].get_weights()[0], -7, 7)\n",
    "int4_s_i2, int4_z_i2 = activation_scale_zero_point(intermediate_output_1_float32, 16)\n",
    "int4_s_b2, int4_z_b2, int4_b2 = bias_arr_quan(model.layers[1].get_weights()[1], int4_s_w2, int4_s_i2)\n",
    "\n",
    "int4_s_w3, int4_z_w3, int4_w3 = weight_arr_quan(model.layers[2].get_weights()[0], -7, 7)\n",
    "int4_s_i3, int4_z_i3 = activation_scale_zero_point(intermediate_output_2_float32, 16)\n",
    "int4_s_b3, int4_z_b3, int4_b3 = bias_arr_quan(model.layers[2].get_weights()[1], int4_s_w3, int4_s_i3)\n",
    "\n",
    "int4_s_w4, int4_z_w4, int4_w4 = weight_arr_quan(model.layers[3].get_weights()[0], -7, 7)\n",
    "int4_s_i4, int4_z_i4 = activation_scale_zero_point(intermediate_output_3_float32, 16)\n",
    "int4_s_b4, int4_z_b4, int4_b4 = bias_arr_quan(model.layers[3].get_weights()[1], int4_s_w4, int4_s_i4)\n",
    "\n",
    "int4_s_o1, int4_z_o1 = int4_s_i2, int4_z_i2\n",
    "int4_s_o2, int4_z_o2 = int4_s_i3, int4_z_i3\n",
    "int4_s_o3, int4_z_o3 = int4_s_i4, int4_z_i4\n",
    "int4_s_o4, int4_z_o4 = activation_scale_zero_point(outputs_float32, 16)\n",
    "\n",
    "model_int4 = Module()\n",
    "model_int4.add_module(FullyConnected(int4_w1.T, int4_b1, int4_s_w1, int4_s_i1, int4_s_o1, int4_z_i1, int4_z_o1, -8, 7), 'l1')\n",
    "model_int4.add_module(FullyConnected(int4_w2.T, int4_b2, int4_s_w2, int4_s_i2, int4_s_o2, int4_z_i2, int4_z_o2, -8, 7), 'l2')\n",
    "model_int4.add_module(FullyConnected(int4_w3.T, int4_b3, int4_s_w3, int4_s_i3, int4_s_o3, int4_z_i3, int4_z_o3, -8, 7), 'l3')\n",
    "model_int4.add_module(FullyConnected(int4_w4.T, int4_b4, int4_s_w4, int4_s_i4, int4_s_o4, int4_z_i4, int4_z_o4, -8, 7), 'l4')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:37.218101Z",
     "end_time": "2023-04-24T15:26:37.540869Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "model_int4_f1 = Module()\n",
    "model_int4_f1.add_module(FullyConnected_f1(int4_w1, int4_b1, int4_s_w1, int4_s_i1, int4_s_o1, int4_z_i1, int4_z_o1, -8, 7), 'l1')\n",
    "model_int4_f1.add_module(FullyConnected_f1(int4_w2, int4_b2, int4_s_w2, int4_s_i2, int4_s_o2, int4_z_i2, int4_z_o2, -8, 7), 'l2')\n",
    "model_int4_f1.add_module(FullyConnected_f1(int4_w3, int4_b3, int4_s_w3, int4_s_i3, int4_s_o3, int4_z_i3, int4_z_o3, -8, 7), 'l3')\n",
    "model_int4_f1.add_module(FullyConnected_f1(int4_w4, int4_b4, int4_s_w4, int4_s_i4, int4_s_o4, int4_z_i4, int4_z_o4, -8, 7), 'l4')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:37.542772Z",
     "end_time": "2023-04-24T15:26:37.594761Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 200)\n",
      "(200, 200)\n",
      "(200, 200)\n",
      "(200, 10)\n"
     ]
    }
   ],
   "source": [
    "model_int4_f2 = Module()\n",
    "model_int4_f2.add_module(FullyConnected_f2(int4_w1.T, int4_b1, int4_s_w1, int4_s_i1, int4_s_o1, int4_z_i1, int4_z_o1, -8, 7), 'l1')\n",
    "model_int4_f2.add_module(FullyConnected_f2(int4_w2.T, int4_b2, int4_s_w2, int4_s_i2, int4_s_o2, int4_z_i2, int4_z_o2, -8, 7), 'l2')\n",
    "model_int4_f2.add_module(FullyConnected_f2(int4_w3.T, int4_b3, int4_s_w3, int4_s_i3, int4_s_o3, int4_z_i3, int4_z_o3, -8, 7), 'l3')\n",
    "model_int4_f2.add_module(FullyConnected_f2(int4_w4.T, int4_b4, int4_s_w4, int4_s_i4, int4_s_o4, int4_z_i4, int4_z_o4, -8, 7), 'l4')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:37.563482Z",
     "end_time": "2023-04-24T15:26:37.610439Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 784)\n",
      "(200, 200)\n",
      "(200, 200)\n",
      "(10, 200)\n"
     ]
    }
   ],
   "source": [
    "model_int4_f3 = Module()\n",
    "model_int4_f3.add_module(FullyConnected_f3(int4_w1, int4_b1, int4_s_w1, int4_s_i1, int4_s_o1, int4_z_i1, int4_z_o1, -8, 7), 'l1')\n",
    "model_int4_f3.add_module(FullyConnected_f3(int4_w2, int4_b2, int4_s_w2, int4_s_i2, int4_s_o2, int4_z_i2, int4_z_o2, -8, 7), 'l2')\n",
    "model_int4_f3.add_module(FullyConnected_f3(int4_w3, int4_b3, int4_s_w3, int4_s_i3, int4_s_o3, int4_z_i3, int4_z_o3, -8, 7), 'l3')\n",
    "model_int4_f3.add_module(FullyConnected_f3(int4_w4, int4_b4, int4_s_w4, int4_s_i4, int4_s_o4, int4_z_i4, int4_z_o4, -8, 7), 'l4')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:37.579195Z",
     "end_time": "2023-04-24T15:26:37.610439Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 200)\n",
      "(200, 200)\n",
      "(200, 200)\n",
      "(200, 10)\n"
     ]
    }
   ],
   "source": [
    "model_int4_f4 = Module()\n",
    "model_int4_f4.add_module(FullyConnected_f4(int4_w1.T, int4_b1, int4_s_w1, int4_s_i1, int4_s_o1, int4_z_i1, int4_z_o1, -8, 7), 'l1')\n",
    "model_int4_f4.add_module(FullyConnected_f4(int4_w2.T, int4_b2, int4_s_w2, int4_s_i2, int4_s_o2, int4_z_i2, int4_z_o2, -8, 7), 'l2')\n",
    "model_int4_f4.add_module(FullyConnected_f4(int4_w3.T, int4_b3, int4_s_w3, int4_s_i3, int4_s_o3, int4_z_i3, int4_z_o3, -8, 7), 'l3')\n",
    "model_int4_f4.add_module(FullyConnected_f4(int4_w4.T, int4_b4, int4_s_w4, int4_s_i4, int4_s_o4, int4_z_i4, int4_z_o4, -8, 7), 'l4')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:37.594761Z",
     "end_time": "2023-04-24T15:26:37.610439Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "int4_w1_encoded = np.zeros(int4_w1.shape, dtype=np.int8)\n",
    "int4_w2_encoded = np.zeros(int4_w2.shape, dtype=np.int8)\n",
    "int4_w3_encoded = np.zeros(int4_w3.shape, dtype=np.int8)\n",
    "int4_w4_encoded = np.zeros(int4_w4.shape, dtype=np.int8)\n",
    "\n",
    "for i in range(int4_w1.shape[0]):\n",
    "    for j in range(int4_w1.shape[1]):\n",
    "        int4_w1_encoded[i][j] = table_code_words[(int4_w1[i][j] + 8)]\n",
    "\n",
    "for i in range(int4_w2.shape[0]):\n",
    "    for j in range(int4_w2.shape[1]):\n",
    "        int4_w2_encoded[i][j] = table_code_words[(int4_w2[i][j] + 8)]\n",
    "\n",
    "for i in range(int4_w3.shape[0]):\n",
    "    for j in range(int4_w3.shape[1]):\n",
    "        int4_w3_encoded[i][j] = table_code_words[(int4_w3[i][j] + 8)]\n",
    "\n",
    "for i in range(int4_w4.shape[0]):\n",
    "    for j in range(int4_w4.shape[1]):\n",
    "        int4_w4_encoded[i][j] = table_code_words[(int4_w4[i][j] + 8)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:37.610439Z",
     "end_time": "2023-04-24T15:26:37.971154Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "model_int4_fullprotection = Module()\n",
    "model_int4_fullprotection.add_module(FullyConnected_fullprotection(int4_w1_encoded.T, int4_b1, int4_s_w1, int4_s_i1, int4_s_o1, int4_z_i1, int4_z_o1, -8, 7), 'l1')\n",
    "model_int4_fullprotection.add_module(FullyConnected_fullprotection(int4_w2_encoded.T, int4_b2, int4_s_w2, int4_s_i2, int4_s_o2, int4_z_i2, int4_z_o2, -8, 7), 'l2')\n",
    "model_int4_fullprotection.add_module(FullyConnected_fullprotection(int4_w3_encoded.T, int4_b3, int4_s_w3, int4_s_i3, int4_s_o3, int4_z_i3, int4_z_o3, -8, 7), 'l3')\n",
    "model_int4_fullprotection.add_module(FullyConnected_fullprotection(int4_w4_encoded.T, int4_b4, int4_s_w4, int4_s_i4, int4_s_o4, int4_z_i4, int4_z_o4, -8, 7), 'l4')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:37.956022Z",
     "end_time": "2023-04-24T15:26:37.971154Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "model_int4_fullprotection_f1 = Module()\n",
    "model_int4_fullprotection_f1.add_module(FullyConnected_fullprotection_f1(int4_w1_encoded, int4_b1, int4_s_w1, int4_s_i1, int4_s_o1, int4_z_i1, int4_z_o1, -8, 7), 'l1')\n",
    "model_int4_fullprotection_f1.add_module(FullyConnected_fullprotection_f1(int4_w2_encoded, int4_b2, int4_s_w2, int4_s_i2, int4_s_o2, int4_z_i2, int4_z_o2, -8, 7), 'l2')\n",
    "model_int4_fullprotection_f1.add_module(FullyConnected_fullprotection_f1(int4_w3_encoded, int4_b3, int4_s_w3, int4_s_i3, int4_s_o3, int4_z_i3, int4_z_o3, -8, 7), 'l3')\n",
    "model_int4_fullprotection_f1.add_module(FullyConnected_fullprotection_f1(int4_w4_encoded, int4_b4, int4_s_w4, int4_s_i4, int4_s_o4, int4_z_i4, int4_z_o4, -8, 7), 'l4')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:37.971154Z",
     "end_time": "2023-04-24T15:26:37.986915Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "model_int4_fullprotection_f2 = Module()\n",
    "model_int4_fullprotection_f2.add_module(FullyConnected_fullprotection_f2(int4_w1_encoded.T, int4_b1, int4_s_w1, int4_s_i1, int4_s_o1, int4_z_i1, int4_z_o1, -8, 7), 'l1')\n",
    "model_int4_fullprotection_f2.add_module(FullyConnected_fullprotection_f2(int4_w2_encoded.T, int4_b2, int4_s_w2, int4_s_i2, int4_s_o2, int4_z_i2, int4_z_o2, -8, 7), 'l2')\n",
    "model_int4_fullprotection_f2.add_module(FullyConnected_fullprotection_f2(int4_w3_encoded.T, int4_b3, int4_s_w3, int4_s_i3, int4_s_o3, int4_z_i3, int4_z_o3, -8, 7), 'l3')\n",
    "model_int4_fullprotection_f2.add_module(FullyConnected_fullprotection_f2(int4_w4_encoded.T, int4_b4, int4_s_w4, int4_s_i4, int4_s_o4, int4_z_i4, int4_z_o4, -8, 7), 'l4')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:37.986915Z",
     "end_time": "2023-04-24T15:26:38.007420Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "model_int4_fullprotection_f3 = Module()\n",
    "model_int4_fullprotection_f3.add_module(FullyConnected_fullprotection_f3(int4_w1_encoded.T, int4_b1, int4_s_w1, int4_s_i1, int4_s_o1, int4_z_i1, int4_z_o1, -8, 7), 'l1')\n",
    "model_int4_fullprotection_f3.add_module(FullyConnected_fullprotection_f3(int4_w2_encoded.T, int4_b2, int4_s_w2, int4_s_i2, int4_s_o2, int4_z_i2, int4_z_o2, -8, 7), 'l2')\n",
    "model_int4_fullprotection_f3.add_module(FullyConnected_fullprotection_f3(int4_w3_encoded.T, int4_b3, int4_s_w3, int4_s_i3, int4_s_o3, int4_z_i3, int4_z_o3, -8, 7), 'l3')\n",
    "model_int4_fullprotection_f3.add_module(FullyConnected_fullprotection_f3(int4_w4_encoded.T, int4_b4, int4_s_w4, int4_s_i4, int4_s_o4, int4_z_i4, int4_z_o4, -8, 7), 'l4')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:38.004739Z",
     "end_time": "2023-04-24T15:26:38.022431Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "model_int4_fullprotection_f4 = Module()\n",
    "model_int4_fullprotection_f4.add_module(FullyConnected_fullprotection_f4(int4_w1_encoded.T, int4_b1, int4_s_w1, int4_s_i1, int4_s_o1, int4_z_i1, int4_z_o1, -8, 7), 'l1')\n",
    "model_int4_fullprotection_f4.add_module(FullyConnected_fullprotection_f4(int4_w2_encoded.T, int4_b2, int4_s_w2, int4_s_i2, int4_s_o2, int4_z_i2, int4_z_o2, -8, 7), 'l2')\n",
    "model_int4_fullprotection_f4.add_module(FullyConnected_fullprotection_f4(int4_w3_encoded.T, int4_b3, int4_s_w3, int4_s_i3, int4_s_o3, int4_z_i3, int4_z_o3, -8, 7), 'l3')\n",
    "model_int4_fullprotection_f4.add_module(FullyConnected_fullprotection_f4(int4_w4_encoded.T, int4_b4, int4_s_w4, int4_s_i4, int4_s_o4, int4_z_i4, int4_z_o4, -8, 7), 'l4')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:38.022431Z",
     "end_time": "2023-04-24T15:26:38.038068Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Patrik\\AppData\\Local\\Temp\\tmpx6569ewl\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dp\\dp\\code\\openvino_notebooks_py37\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in train_images_float32:\n",
    "        yield [input_value]\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Set the input and output tensors to int8\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:38.038068Z",
     "end_time": "2023-04-24T15:26:40.194106Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "tflite_models_dir = pathlib.Path(\"models\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "model_path = r\"models/mnist_int8_tflite_model_layers4_neurons200-200-200-10.tflite\"\n",
    "\n",
    "# Save the model:\n",
    "int8_tflite_model_file = tflite_models_dir / \"mnist_int8_tflite_model_layers4_neurons200-200-200-10.tflite\"\n",
    "if not int8_tflite_model_file.is_file():\n",
    "    int8_tflite_model_file.write_bytes(tflite_model_quant)\n",
    "    print(\"Model saved to: \", int8_tflite_model_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:40.194106Z",
     "end_time": "2023-04-24T15:26:40.209615Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "tflite_file = pathlib.Path('.\\models\\mnist_int8_tflite_model_layers4_neurons200-200-200-10.tflite')\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index_interpreter = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index_interpreter = interpreter.get_output_details()[0][\"index\"]\n",
    "input_details_interpreter = interpreter.get_input_details()[0]\n",
    "input_scale_interpreter, input_zero_point_interpreter = input_details_interpreter[\"quantization\"]\n",
    "\n",
    "def run_tflite_model(interpreter, input):\n",
    "\n",
    "    test_image = input / input_scale_interpreter + input_zero_point_interpreter\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details_interpreter[\"dtype\"])\n",
    "\n",
    "    eva_time_all = time.time()\n",
    "    interpreter.set_tensor(input_index_interpreter, test_image)\n",
    "    eva_time_invoke = time.time()\n",
    "    interpreter.invoke()\n",
    "    eva_time_invoke = time.time() - eva_time_invoke\n",
    "    output = interpreter.get_tensor(output_index_interpreter)\n",
    "    eva_time_all = time.time() - eva_time_all\n",
    "\n",
    "    return output, eva_time_invoke, eva_time_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T15:26:40.209615Z",
     "end_time": "2023-04-24T15:26:40.241001Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 1000\n",
      "00:00:16.90\n",
      "acc_int4_f1                :  0.96\n",
      "acc_int4_fullprotection_f1 :  0.96\n",
      "acc_int8_tf                :  0.976\n",
      "eva_time_f1                 : 0.0007541589736938477\n",
      "eva_time_fullprotection_f1  : 0.016041678190231324\n",
      "eva_time_int8_tf_invoke     : 1.606893539428711e-05\n",
      "eva_time_int8_tf_all        : 3.25007438659668e-05\n",
      "----------------------------------------------------------------------------\n",
      "done 2000\n",
      "00:00:16.79\n",
      "acc_int4_f1                :  0.943\n",
      "acc_int4_fullprotection_f1 :  0.943\n",
      "acc_int8_tf                :  0.968\n",
      "eva_time_f1                 : 0.000771005630493164\n",
      "eva_time_fullprotection_f1  : 0.01594717013835907\n",
      "eva_time_int8_tf_invoke     : 8.034467697143554e-06\n",
      "eva_time_int8_tf_all        : 2.4065375328063965e-05\n",
      "----------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_4656\\3075232193.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    122\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    123\u001B[0m     \u001B[0meva_time_s\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 124\u001B[1;33m     \u001B[0moutput_model_int4_fullprotection_f1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_int4_fullprotection_f1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_int4\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    125\u001B[0m     \u001B[0meva_time_fullprotection_f1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0meva_time_fullprotection_f1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0meva_time_s\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    126\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_4656\\489779698.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m      9\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodules\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m             \u001B[1;31m# print(f\"module: {module}\")\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodules\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmodule\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_4656\\489779698.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m         \u001B[0mW_decoded\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvectorize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0merror_correction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getitem__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mW_encoded\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m         \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mint32\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mint32\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mW_decoded\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     60\u001B[0m         \u001B[0ma2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mint32\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mW_decoded\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "dif = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "correct_int4 = 0\n",
    "correct_int4_f1 = 0\n",
    "correct_int4_f2 = 0\n",
    "correct_int4_f3 = 0\n",
    "correct_int4_f4 = 0\n",
    "correct_int4_fullprotection = 0\n",
    "correct_int4_fullprotection_f1 = 0\n",
    "correct_int4_fullprotection_f2 = 0\n",
    "correct_int4_fullprotection_f3 = 0\n",
    "correct_int4_fullprotection_f4 = 0\n",
    "correct_int8_tf = 0\n",
    "\n",
    "mistakes_int4 = np.array([])\n",
    "mistakes_int4_f1 = np.array([])\n",
    "mistakes_int4_f2 = np.array([])\n",
    "mistakes_int4_f3 = np.array([])\n",
    "mistakes_int4_f4 = np.array([])\n",
    "mistakes_int4_fullprotection = np.array([])\n",
    "mistakes_int4_fullprotection_f1 = np.array([])\n",
    "mistakes_int4_fullprotection_f2 = np.array([])\n",
    "mistakes_int4_fullprotection_f3 = np.array([])\n",
    "mistakes_int4_fullprotection_f4 = np.array([])\n",
    "mistakes_int8_tf = np.array([])\n",
    "\n",
    "eva_time = np.array([])\n",
    "eva_time_f1 = np.array([])\n",
    "eva_time_f2 = np.array([])\n",
    "eva_time_f3 = np.array([])\n",
    "eva_time_f4 = np.array([])\n",
    "eva_time_fullprotection = np.array([])\n",
    "eva_time_fullprotection_f1 = np.array([])\n",
    "eva_time_fullprotection_f2 = np.array([])\n",
    "eva_time_fullprotection_f3 = np.array([])\n",
    "eva_time_fullprotection_f4 = np.array([])\n",
    "eva_time_int8_tf_invoke = np.array([])\n",
    "eva_time_int8_tf_all = np.array([])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(eva_images_float32.shape[0]):\n",
    "# for i in range(1000):\n",
    "\n",
    "    if i % 1000 == 0 and i != 0:\n",
    "\n",
    "        hours, rem = divmod(time.time()-round_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "        print(f\"done {i}\")\n",
    "        print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "        # print(\"acc_int4                   : \", correct_int4 / i)\n",
    "        print(\"acc_int4_f1                : \", correct_int4_f1 / i)\n",
    "        # print(\"acc_int4_f2                : \", correct_int4_f2 / i)\n",
    "        # print(\"acc_int4_f3                : \", correct_int4_f3 / i)\n",
    "        # print(\"acc_int4_f4                : \", correct_int4_f4 / i)\n",
    "        # print(\"acc_int4_fullprotection    : \", correct_int4_fullprotection / i)\n",
    "        print(\"acc_int4_fullprotection_f1 : \", correct_int4_fullprotection_f1 / i)\n",
    "        # print(\"acc_int4_fullprotection_f2 : \", correct_int4_fullprotection_f2 / i)\n",
    "        # print(\"acc_int4_fullprotection_f3 : \", correct_int4_fullprotection_f3 / i)\n",
    "        # print(\"acc_int4_fullprotection_f4 : \", correct_int4_fullprotection_f4 / i)\n",
    "        print(\"acc_int8_tf                : \", correct_int8_tf / i)\n",
    "\n",
    "\n",
    "        # print(\"dif_f1: \", dif[0] / i)\n",
    "        # print(\"dif_f2: \", dif[1] / i)\n",
    "        # print(\"dif_f3: \", dif[2] / i)\n",
    "        # print(\"dif_f4: \", dif[3] / i)\n",
    "        # print(\"dif_fullprotection: \", dif[4] / i)\n",
    "        # print(\"dif_fullprotection_f1: \", dif[5] / i)\n",
    "        # print(\"dif_fullprotection_f2: \", dif[6] / i)\n",
    "        # print(\"dif_fullprotection_f3: \", dif[7] / i)\n",
    "        # print(\"dif_fullprotection_f4: \", dif[8] / i)\n",
    "\n",
    "\n",
    "        # print(f'eva_time                    : {np.mean(eva_time)}')\n",
    "        print(f'eva_time_f1                 : {np.mean(eva_time_f1)}')\n",
    "        # print(f'eva_time_f2                 : {np.mean(eva_time_f2)}')\n",
    "        # print(f'eva_time_f3                 : {np.mean(eva_time_f3)}')\n",
    "        # print(f'eva_time_f4                 : {np.mean(eva_time_f4)}')\n",
    "        # print(f'eva_time_fullprotection     : {np.mean(eva_time_fullprotection)}')\n",
    "        print(f'eva_time_fullprotection_f1  : {np.mean(eva_time_fullprotection_f1)}')\n",
    "        # print(f'eva_time_fullprotection_f2  : {np.mean(eva_time_fullprotection_f2)}')\n",
    "        # print(f'eva_time_fullprotection_f3  : {np.mean(eva_time_fullprotection_f3)}')\n",
    "        # print(f'eva_time_fullprotection_f4  : {np.mean(eva_time_fullprotection_f4)}')\n",
    "        print(f'eva_time_int8_tf_invoke     : {np.mean(eva_time_int8_tf_invoke)}')\n",
    "        print(f'eva_time_int8_tf_all        : {np.mean(eva_time_int8_tf_all)}')\n",
    "        print(\"----------------------------------------------------------------------------\")\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        round_time = time.time()\n",
    "\n",
    "    input_int4 = eva_images_float32[i]\n",
    "    input_int4 = input_int4 / int4_s_i1 + int4_z_i1\n",
    "    input_int4 = np.expand_dims(input_int4, axis=0).astype(np.int8)\n",
    "\n",
    "    input_int8_tf = eva_images_float32[i]\n",
    "\n",
    "    # eva_time_s = time.time()\n",
    "    # output_model_int4 = model_int4.forward(input_int4)\n",
    "    # eva_time = np.append(eva_time, time.time() - eva_time_s)\n",
    "\n",
    "    eva_time_s = time.time()\n",
    "    output_model_int4_f1 = model_int4_f1.forward(input_int4)\n",
    "    eva_time_f1 = np.append(eva_time_f1, time.time() - eva_time_s)\n",
    "\n",
    "    # eva_time_s = time.time()\n",
    "    # output_model_int4_f2 = model_int4_f2.forward(input_int4)\n",
    "    # eva_time_f2 = np.append(eva_time_f2, time.time() - eva_time_s)\n",
    "    #\n",
    "    # eva_time_s = time.time()\n",
    "    # output_model_int4_f3 = model_int4_f3.forward(input_int4)\n",
    "    # eva_time_f3 = np.append(eva_time_f3, time.time() - eva_time_s)\n",
    "    #\n",
    "    # eva_time_s = time.time()\n",
    "    # output_model_int4_f4 = model_int4_f4.forward(input_int4)\n",
    "    # eva_time_f4 = np.append(eva_time_f4, time.time() - eva_time_s)\n",
    "    #\n",
    "    # eva_time_s = time.time()\n",
    "    # output_model_int4_fullprotection = model_int4_fullprotection.forward(input_int4)\n",
    "    # eva_time_fullprotection = np.append(eva_time_fullprotection, time.time() - eva_time_s)\n",
    "\n",
    "    eva_time_s = time.time()\n",
    "    output_model_int4_fullprotection_f1 = model_int4_fullprotection_f1.forward(input_int4)\n",
    "    eva_time_fullprotection_f1 = np.append(eva_time_fullprotection_f1, time.time() - eva_time_s)\n",
    "\n",
    "    # eva_time_s = time.time()\n",
    "    # output_model_int4_fullprotection_f2 = model_int4_fullprotection_f2.forward(input_int4)\n",
    "    # eva_time_fullprotection_f2 = np.append(eva_time_fullprotection_f2, time.time() - eva_time_s)\n",
    "    #\n",
    "    # eva_time_s = time.time()\n",
    "    # output_model_int4_fullprotection_f3 = model_int4_fullprotection_f3.forward(input_int4)\n",
    "    # eva_time_fullprotection_f3 = np.append(eva_time_fullprotection_f3, time.time() - eva_time_s)\n",
    "    #\n",
    "    # eva_time_s = time.time()\n",
    "    # output_model_int4_fullprotection_f4 = model_int4_fullprotection_f4.forward(input_int4)\n",
    "    # eva_time_fullprotection_f4 = np.append(eva_time_fullprotection_f4, time.time() - eva_time_s)\n",
    "\n",
    "    output_model_int8_tf, time_tf_invoke, time_tf_all = run_tflite_model(interpreter, input_int8_tf)\n",
    "    eva_time_int8_tf_invoke = np.append(eva_time_int8_tf_invoke, time_tf_invoke)\n",
    "    eva_time_int8_tf_all = np.append(eva_time_int8_tf_all, time_tf_all)\n",
    "\n",
    "    # dif[0] += np.sum(np.abs(output_model_int4 - output_model_int4_f1))\n",
    "    # dif[1] += np.sum(np.abs(output_model_int4 - output_model_int4_f2))\n",
    "    # dif[2] += np.sum(np.abs(output_model_int4 - output_model_int4_f3))\n",
    "    # dif[3] += np.sum(np.abs(output_model_int4 - output_model_int4_f4))\n",
    "    # dif[4] += np.sum(np.abs(output_model_int4 - output_model_int4_fullprotection))\n",
    "    # dif[5] += np.sum(np.abs(output_model_int4 - output_model_int4_fullprotection_f1))\n",
    "    # dif[6] += np.sum(np.abs(output_model_int4 - output_model_int4_fullprotection_f2))\n",
    "    # dif[7] += np.sum(np.abs(output_model_int4 - output_model_int4_fullprotection_f3))\n",
    "    # dif[8] += np.sum(np.abs(output_model_int4 - output_model_int4_fullprotection_f4))\n",
    "\n",
    "    # answer_int4 = np.argmax(output_model_int4)\n",
    "    answer_int4_f1 = np.argmax(output_model_int4_f1)\n",
    "    # answer_int4_f2 = np.argmax(output_model_int4_f2)\n",
    "    # answer_int4_f3 = np.argmax(output_model_int4_f3)\n",
    "    # answer_int4_f4 = np.argmax(output_model_int4_f4)\n",
    "    # answer_int4_fullprotection = np.argmax(output_model_int4_fullprotection)\n",
    "    answer_int4_fullprotection_f1 = np.argmax(output_model_int4_fullprotection_f1)\n",
    "    # answer_int4_fullprotection_f2 = np.argmax(output_model_int4_fullprotection_f2)\n",
    "    # answer_int4_fullprotection_f3 = np.argmax(output_model_int4_fullprotection_f3)\n",
    "    # answer_int4_fullprotection_f4 = np.argmax(output_model_int4_fullprotection_f4)\n",
    "    answer_int8_tf = np.argmax(output_model_int8_tf)\n",
    "\n",
    "\n",
    "    # if answer_int4 == eva_labels[i]:\n",
    "    #     correct_int4 += 1\n",
    "    # else:\n",
    "    #     mistakes_int4 = np.append(mistakes_int4, i)\n",
    "\n",
    "    if answer_int4_f1 == eva_labels[i]:\n",
    "        correct_int4_f1 += 1\n",
    "    else:\n",
    "        mistakes_int4_f1 = np.append(mistakes_int4_f1, i)\n",
    "\n",
    "    # if answer_int4_f2 == eva_labels[i]:\n",
    "    #     correct_int4_f2 += 1\n",
    "    # else:\n",
    "    #     mistakes_int4_f2 = np.append(mistakes_int4_f2, i)\n",
    "    #\n",
    "    # if answer_int4_f3 == eva_labels[i]:\n",
    "    #     correct_int4_f3 += 1\n",
    "    # else:\n",
    "    #     mistakes_int4_f3 = np.append(mistakes_int4_f3, i)\n",
    "    #\n",
    "    # if answer_int4_f4 == eva_labels[i]:\n",
    "    #     correct_int4_f4 += 1\n",
    "    # else:\n",
    "    #     mistakes_int4_f4 = np.append(mistakes_int4_f4, i)\n",
    "    #\n",
    "    # if answer_int4_fullprotection == eva_labels[i]:\n",
    "    #     correct_int4_fullprotection += 1\n",
    "    # else:\n",
    "    #     mistakes_int4_fullprotection = np.append(mistakes_int4_fullprotection, i)\n",
    "\n",
    "    if answer_int4_fullprotection_f1 == eva_labels[i]:\n",
    "        correct_int4_fullprotection_f1 += 1\n",
    "    else:\n",
    "        mistakes_int4_fullprotection_f1 = np.append(mistakes_int4_fullprotection_f1, i)\n",
    "\n",
    "    # if answer_int4_fullprotection_f2 == eva_labels[i]:\n",
    "    #     correct_int4_fullprotection_f2 += 1\n",
    "    # else:\n",
    "    #     mistakes_int4_fullprotection_f2 = np.append(mistakes_int4_fullprotection_f2, i)\n",
    "    #\n",
    "    # if answer_int4_fullprotection_f3 == eva_labels[i]:\n",
    "    #     correct_int4_fullprotection_f3 += 1\n",
    "    # else:\n",
    "    #     mistakes_int4_fullprotection_f3 = np.append(mistakes_int4_fullprotection_f3, i)\n",
    "    #\n",
    "    # if answer_int4_fullprotection_f4 == eva_labels[i]:\n",
    "    #     correct_int4_fullprotection_f4 += 1\n",
    "    # else:\n",
    "    #     mistakes_int4_fullprotection_f4 = np.append(mistakes_int4_fullprotection_f4, i)\n",
    "\n",
    "    if answer_int8_tf == eva_labels[i]:\n",
    "        correct_int8_tf += 1\n",
    "    else:\n",
    "        mistakes_int8_tf = np.append(mistakes_int8_tf, i)\n",
    "\n",
    "\n",
    "hours, rem = divmod(time.time()-start_time, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "\n",
    "# np.save('mistakes_faster_int4_layers4_neurons200-200-200-10/dif_f1_f2_f3_f4_fp_fpf1_fpf2_fpf3_fpf4.npy', dif)\n",
    "# np.save('mistakes_faster_int4_layers4_neurons200-200-200-10/mistakes_int4.npy', mistakes_int4)\n",
    "# np.save('mistakes_faster_int4_layers4_neurons200-200-200-10/mistakes_int4_f1.npy', mistakes_int4_f1)\n",
    "# np.save('mistakes_faster_int4_layers4_neurons200-200-200-10/mistakes_int4_f2.npy', mistakes_int4_f2)\n",
    "# np.save('mistakes_faster_int4_layers4_neurons200-200-200-10/mistakes_int4_f3.npy', mistakes_int4_f3)\n",
    "# np.save('mistakes_faster_int4_layers4_neurons200-200-200-10/mistakes_int4_f4.npy', mistakes_int4_f4)\n",
    "# np.save('mistakes_faster_int4_layers4_neurons200-200-200-10/mistakes_int4_fullprotection.npy', mistakes_int4_fullprotection)\n",
    "# np.save('mistakes_faster_int4_layers4_neurons200-200-200-10/mistakes_int4_fullprotection_f1.npy', mistakes_int4_fullprotection_f1)\n",
    "# np.save('mistakes_faster_int4_layers4_neurons200-200-200-10/mistakes_int4_fullprotection_f2.npy', mistakes_int4_fullprotection_f2)\n",
    "# np.save('mistakes_faster_int4_layers4_neurons200-200-200-10/mistakes_int4_fullprotection_f3.npy', mistakes_int4_fullprotection_f3)\n",
    "# np.save('mistakes_faster_int4_layers4_neurons200-200-200-10/mistakes_int4_fullprotection_f4.npy', mistakes_int4_fullprotection_f4)\n",
    "# np.save('mistakes_faster_int4_layers4_neurons200-200-200-10/mistakes_int8_tf.npy', mistakes_int8_tf)\n",
    "\n",
    "# mistake_output_1 = np.sum(dif[0]) / eva_images_float32.shape[0]\n",
    "# mistake_value_1 = mistake_output_1 / 10\n",
    "#\n",
    "# mistake_output_2 = np.sum(dif[1]) / eva_images_float32.shape[0]\n",
    "# mistake_value_2 = mistake_output_2 / 10\n",
    "#\n",
    "# mistake_output_3 = np.sum(dif[2]) / eva_images_float32.shape[0]\n",
    "# mistake_value_3 = mistake_output_3 / 10\n",
    "#\n",
    "# mistake_output_4 = np.sum(dif[3]) / eva_images_float32.shape[0]\n",
    "# mistake_value_4 = mistake_output_4 / 10\n",
    "#\n",
    "# mistake_output_5 = np.sum(dif[4]) / eva_images_float32.shape[0]\n",
    "# mistake_value_5 = mistake_output_5 / 10\n",
    "#\n",
    "# mistake_output_6 = np.sum(dif[5]) / eva_images_float32.shape[0]\n",
    "# mistake_value_6 = mistake_output_6 / 10\n",
    "#\n",
    "# mistake_output_7 = np.sum(dif[6]) / eva_images_float32.shape[0]\n",
    "# mistake_value_7 = mistake_output_7 / 10\n",
    "#\n",
    "# mistake_output_8 = np.sum(dif[7]) / eva_images_float32.shape[0]\n",
    "# mistake_value_8 = mistake_output_8 / 10\n",
    "#\n",
    "# mistake_output_9 = np.sum(dif[8]) / eva_images_float32.shape[0]\n",
    "# mistake_value_9 = mistake_output_9 / 10\n",
    "#\n",
    "# print(f'Mistake1 in output: {mistake_output_1}')\n",
    "# print(f'Mistake1 in value: {mistake_value_1}\\n')\n",
    "# print(f'Mistake2 in output: {mistake_output_2}')\n",
    "# print(f'Mistake2 in value: {mistake_value_2}\\n')\n",
    "# print(f'Mistake3 in output: {mistake_output_3}')\n",
    "# print(f'Mistake3 in value: {mistake_value_3}\\n')\n",
    "# print(f'Mistake4 in output: {mistake_output_4}')\n",
    "# print(f'Mistake4 in value: {mistake_value_4}\\n')\n",
    "# print(f'Mistake5 in output: {mistake_output_5}')\n",
    "# print(f'Mistake5 in value: {mistake_value_5}\\n')\n",
    "# print(f'Mistake6 in output: {mistake_output_6}')\n",
    "# print(f'Mistake6 in value: {mistake_value_6}\\n')\n",
    "# print(f'Mistake7 in output: {mistake_output_7}')\n",
    "# print(f'Mistake7 in value: {mistake_value_7}\\n')\n",
    "# print(f'Mistake8 in output: {mistake_output_8}')\n",
    "# print(f'Mistake8 in value: {mistake_value_8}\\n')\n",
    "# print(f'Mistake9 in output: {mistake_output_9}')\n",
    "# print(f'Mistake9 in value: {mistake_value_9}\\n')\n",
    "\n",
    "print('Accuracy float32                : ', model.evaluate(eva_images_float32, eva_labels)[1])\n",
    "# print('Accuracy int4                   : ', correct_int4 / eva_images_float32.shape[0])\n",
    "print('Accuracy int4 f1                : ', correct_int4_f1 / eva_images_float32.shape[0])\n",
    "# print('Accuracy int4 f2                : ', correct_int4_f2 / eva_images_float32.shape[0])\n",
    "# print('Accuracy int4 f3                : ', correct_int4_f3 / eva_images_float32.shape[0])\n",
    "# print('Accuracy int4 f4                : ', correct_int4_f4 / eva_images_float32.shape[0])\n",
    "# print('Accuracy int4 fullprotection    : ', correct_int4_fullprotection / eva_images_float32.shape[0])\n",
    "print('Accuracy int4 fullprotection f1 : ', correct_int4_fullprotection_f1 / eva_images_float32.shape[0])\n",
    "# print('Accuracy int4 fullprotection f2 : ', correct_int4_fullprotection_f2 / eva_images_float32.shape[0])\n",
    "# print('Accuracy int4 fullprotection f3 : ', correct_int4_fullprotection_f3 / eva_images_float32.shape[0])\n",
    "# print('Accuracy int4 fullprotection f4 : ', correct_int4_fullprotection_f4 / eva_images_float32.shape[0])\n",
    "print('Accuracy int8 tf                : ', correct_int8_tf / eva_images_float32.shape[0])\n",
    "\n",
    "\n",
    "# print(f'eva_time                   : {np.mean(eva_time)}')\n",
    "print(f'eva_time_f1                : {np.mean(eva_time_f1)}')\n",
    "# print(f'eva_time_f2                : {np.mean(eva_time_f2)}')\n",
    "# print(f'eva_time_f3                : {np.mean(eva_time_f3)}')\n",
    "# print(f'eva_time_f4                : {np.mean(eva_time_f4)}')\n",
    "# print(f'eva_time_fullprotection    : {np.mean(eva_time_fullprotection)}')\n",
    "print(f'eva_time_fullprotection_f1 : {np.mean(eva_time_fullprotection_f1)}')\n",
    "# print(f'eva_time_fullprotection_f2 : {np.mean(eva_time_fullprotection_f2)}')\n",
    "# print(f'eva_time_fullprotection_f3 : {np.mean(eva_time_fullprotection_f3)}')\n",
    "# print(f'eva_time_fullprotection_f4 : {np.mean(eva_time_fullprotection_f4)}')\n",
    "print(f'eva_time_int8_tf_all       : {np.mean(eva_time_int8_tf_all)}')\n",
    "print(f'eva_time_int8_tf_invoke    : {np.mean(eva_time_int8_tf_invoke)}')\n",
    "\n",
    "print('------------------------------------\\nHow much faster (eva_time is x times faster then eva_time_fp):\\n')\n",
    "\n",
    "# print(f'eva_time       - eva_time_fp    : {np.mean(eva_time_fullprotection)/np.mean(eva_time)}')\n",
    "# print(f'eva_time_f1    - eva_time       : {np.mean(eva_time)/np.mean(eva_time_f1)}')\n",
    "# print(f'eva_time_f2    - eva_time       : {np.mean(eva_time)/np.mean(eva_time_f2)}')\n",
    "# print(f'eva_time_f3    - eva_time       : {np.mean(eva_time)/np.mean(eva_time_f3)}')\n",
    "# print(f'eva_time_f4    - eva_time       : {np.mean(eva_time)/np.mean(eva_time_f4)}')\n",
    "# print(f'eva_time_fp_f1 - eva_time_fp    : {np.mean(eva_time_fullprotection)/np.mean(eva_time_fullprotection_f1)}')\n",
    "# print(f'eva_time_fp_f2 - eva_time_fp    : {np.mean(eva_time_fullprotection)/np.mean(eva_time_fullprotection_f2)}')\n",
    "# print(f'eva_time_fp_f3 - eva_time_fp    : {np.mean(eva_time_fullprotection)/np.mean(eva_time_fullprotection_f3)}')\n",
    "# print(f'eva_time_fp_f4 - eva_time_fp    : {np.mean(eva_time_fullprotection)/np.mean(eva_time_fullprotection_f4)}')\n",
    "print(f'eva_time_f1    - eva_time_fp_f1 : {np.mean(eva_time_fullprotection_f1)/np.mean(eva_time_f1)}')\n",
    "# print(f'eva_time_f2    - eva_time_fp_f2 : {np.mean(eva_time_fullprotection_f2)/np.mean(eva_time_f2)}')\n",
    "# print(f'eva_time_f3    - eva_time_fp_f3 : {np.mean(eva_time_fullprotection_f3)/np.mean(eva_time_f3)}')\n",
    "# print(f'eva_time_f4    - eva_time_fp_f4 : {np.mean(eva_time_fullprotection_f4)/np.mean(eva_time_f4)}')\n",
    "print(f'eva_time_int8_tf_invoke - eva_time_int8_tf_all : {np.mean(eva_time_int8_tf_all)/np.mean(eva_time_int8_tf_invoke)}')\n",
    "\n",
    "print('eva_time_fp_f1_10k   : ',np.sum(eva_time_fullprotection_f1))\n",
    "print('eva_time_f1_10k      : ',np.sum(eva_time_f1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T14:50:00.972124Z",
     "end_time": "2023-04-24T14:52:33.032201Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T14:52:33.016589Z",
     "end_time": "2023-04-24T14:52:33.032201Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
