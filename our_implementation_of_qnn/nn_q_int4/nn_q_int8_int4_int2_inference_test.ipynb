{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This is designed for inference calculation only"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.DEBUG)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import netron"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T20:12:13.031624Z",
     "end_time": "2023-04-09T20:12:14.957230Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation mnist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size: 28, input_size: 784\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (eva_images, eva_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images_float32_28x28 = train_images.astype(np.float32) / 255.0\n",
    "eva_images_float32_28x28 = eva_images.astype(np.float32) / 255.0\n",
    "\n",
    "# Normalize the input image so that each pixel value is between -128 and 127.\n",
    "train_images_int8 = np.int8(train_images.astype(np.float32) - 128.0)\n",
    "eva_images_int8 = np.int8(eva_images.astype(np.float32) - 128.0)\n",
    "\n",
    "# image dimensions (assumed square)\n",
    "image_size = train_images_float32_28x28.shape[1]\n",
    "input_size = image_size * image_size\n",
    "print(f'image_size: {image_size}, input_size: {input_size}')\n",
    "\n",
    "#reshape data to fit model\n",
    "train_images_float32 = np.reshape(train_images_float32_28x28, [-1, input_size])\n",
    "eva_images_float32 = np.reshape(eva_images_float32_28x28, [-1, input_size])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T20:12:14.957230Z",
     "end_time": "2023-04-09T20:12:15.507064Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Manual calculation of Inference for quantized nn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self.modules = OrderedDict()\n",
    "\n",
    "    def add_module(self, module, name:str):\n",
    "        self.modules[name] = module\n",
    "\n",
    "    def forward(self, input) -> np.ndarray:\n",
    "        for module in self.modules:\n",
    "            # print(f\"module: {module}\")\n",
    "            input = self.modules[module].forward(input)\n",
    "\n",
    "        return input"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T20:12:15.507064Z",
     "end_time": "2023-04-09T20:12:15.554372Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#   FullyConnected class\n",
    "#------------------------------------------------------------------------------\n",
    "class FullyConnected(Module):\n",
    "    def __init__(self, w, b, s_w, s_i, s_o, z_i, z_o, min_T, max_T):\n",
    "        super(FullyConnected, self).__init__()\n",
    "        self.W = w\n",
    "        self.b = b\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.m = s_i * s_w / s_o\n",
    "        self.s_b = s_i * s_w\n",
    "        self.min_T = min_T\n",
    "        self.max_T = max_T\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        output_int8 = np.zeros((input.shape[0], self.W.shape[1]), dtype=np.int8)\n",
    "        output = np.zeros((input.shape[0], self.W.shape[1]), dtype=np.int32)\n",
    "        a2 = np.zeros((self.W.shape[1]), dtype=np.int32)\n",
    "\n",
    "        for i in range(input.shape[0]):\n",
    "            for k in range(self.W.shape[1]):\n",
    "                for j in range(input.shape[1]):\n",
    "                    a2[k] += np.int32(self.W[j][k])\n",
    "                    output[i][k] += np.int32(input[i][j]) * np.int32(self.W[j][k])\n",
    "\n",
    "                    # print(f'i = {input[i][j]}, W = {self.W[j][k]}, output_32 = {output[i][k]}, a2={a2[k]}')\n",
    "\n",
    "                # print('-----------------')\n",
    "                # print(f'z_o = {self.z_o}, m = {self.m}, o = {output[i][k]}, b = {self.b[k]}, a2 = {a2[k]}, z_i = {self.z_i}, zia2: {-self.z_i*a2[k]}')\n",
    "                # print(f'output_before_saturate_cast = ',np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k]))\n",
    "\n",
    "                # output_int8[i][k] = tf.dtypes.saturate_cast(np.round(np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k])), tf.int8)\n",
    "\n",
    "                ourput_value = np.round(np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k]))\n",
    "\n",
    "                if ourput_value > self.max_T:\n",
    "                    output_int8[i][k] = np.int8(self.max_T)\n",
    "                elif ourput_value < self.min_T:\n",
    "                    output_int8[i][k] = np.int8(self.min_T)\n",
    "                else:\n",
    "                    output_int8[i][k] = np.int8(ourput_value)\n",
    "\n",
    "                # print('output_int8: ', output_int8[i][k])\n",
    "                # print('-----------------')\n",
    "\n",
    "        # print(f'input: {input} \\noutput: {output_int8}\\n-----------------\\n-----------------')\n",
    "        # print(f'input: {input.dtype} \\noutput2: {output_int8.dtype}\\n-----------------')\n",
    "\n",
    "        return output_int8\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   Quantize class\n",
    "#------------------------------------------------------------------------------\n",
    "class Quantize(Module):\n",
    "    def __init__(self, s, z_i, z_o, d_type):\n",
    "        super(Quantize, self).__init__()\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.s = s\n",
    "        self.d_type = d_type\n",
    "\n",
    "        # print(f'Quantize: z_i: {self.z_i} z_o: {self.z_o} s: {self.s} d_type: {self.d_type}')\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        # converts from int8 to uint8 and vice versa\n",
    "        if self.d_type is np.int8:\n",
    "            arr_q = (input + 128).astype(np.uint8)\n",
    "        elif self.d_type is np.uint8:\n",
    "            arr_q = (input - 128).astype(np.int8)\n",
    "        else:\n",
    "            raise ValueError(f'input type is not supported: {input.dtype}')\n",
    "\n",
    "        # print(f'input: {input} \\noutput: {arr_q}\\n-----------------\\n-----------------')\n",
    "        # print(f'input: {input.dtype} \\noutput: {arr_q.dtype}\\n-----------------')\n",
    "\n",
    "        return arr_q\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T20:12:15.522681Z",
     "end_time": "2023-04-09T20:12:15.554372Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Calculation of a, b parameters\n",
    "\n",
    "def calculation_a_b(input_array):\n",
    "    return np.min(input_array), np.max(input_array)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Weight quantization\n",
    "\n",
    "def weight_scaling_factor(a, b, min_T, max_T):\n",
    "    s_a = a / min_T\n",
    "    s_b = b / max_T\n",
    "\n",
    "    if s_a > s_b:\n",
    "        return s_a, a, max_T * s_a\n",
    "    else:\n",
    "        return s_b, min_T * s_b, b\n",
    "\n",
    "def clamp(r,a,b):\n",
    "    return min(max(r, a), b)\n",
    "\n",
    "def weight_quan(r, a, b, min_T, s):\n",
    "\n",
    "    q_value = np.round((clamp(r,a,b) - a) / s) + min_T\n",
    "\n",
    "    # print(f'q_value: {q_value}')\n",
    "\n",
    "    z = 0\n",
    "    r = s * (q_value - z)\n",
    "\n",
    "    # print(f'r: {r}')\n",
    "\n",
    "    return q_value\n",
    "\n",
    "def weight_arr_quan(input_arr, min_T, max_T):\n",
    "\n",
    "    a, b = calculation_a_b(input_arr)\n",
    "    s, a, b = weight_scaling_factor(a, b, min_T, max_T)\n",
    "\n",
    "    out_arr = np.zeros(input_arr.shape, dtype=np.int8).T\n",
    "\n",
    "    for i in range(input_arr.shape[0]):\n",
    "        for j in range(input_arr.shape[1]):\n",
    "            out_arr[j][i] = weight_quan(input_arr[i][j], a, b, min_T, s)\n",
    "\n",
    "    return s, 0, out_arr\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Activation quantization\n",
    "\n",
    "def activation_scaling_factor(a, b, n):\n",
    "   return (b - a) / (n - 1)\n",
    "\n",
    "def activation_scale_zero_point(input_array, n):\n",
    "    a, b = calculation_a_b(input_array)\n",
    "    s = activation_scaling_factor(a, b, n)\n",
    "    q_value = np.round((0 - a) / s) - n/2\n",
    "    z = q_value - (0 / s)\n",
    "\n",
    "    print(f's: {s} \\nz: {z}')\n",
    "\n",
    "    return s, z\n",
    "\n",
    "def activation_quan(r, a, b, n, s, z):\n",
    "\n",
    "    q_value = np.round((clamp(r,a,b) - a) / s) - n/2\n",
    "\n",
    "    print(f'q_value: {q_value}')\n",
    "\n",
    "    r = s * (q_value - z)\n",
    "    print(f'r: {r}')\n",
    "\n",
    "    return q_value\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Bias quantization\n",
    "\n",
    "def bias_quan(r, s_w, s_i):\n",
    "    return np.round(r / (s_i * s_w))\n",
    "\n",
    "def bias_arr_quan(arr, s_w, s_i):\n",
    "\n",
    "    arr = np.array([bias_quan(r, s_w, s_i) for r in arr], dtype=np.int32)\n",
    "    s = s_w * s_i\n",
    "\n",
    "    return s, 0, arr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T20:12:15.538706Z",
     "end_time": "2023-04-09T20:12:15.554372Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model float32 TF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 512us/step\n",
      "1875/1875 [==============================] - 1s 556us/step\n"
     ]
    }
   ],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(20, activation='relu', input_dim=input_size),\n",
    "    tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "model.load_weights(r'models/mnist_float_nn_tf/mnist_float_weights')\n",
    "\n",
    "# Define a new model that outputs the intermediate layer\n",
    "intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
    "\n",
    "# Get the intermediate output for the entire input dataset\n",
    "intermediate_output_float32 = intermediate_model.predict(train_images_float32)\n",
    "\n",
    "outputs_float32 = model.predict(train_images_float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T20:12:15.554372Z",
     "end_time": "2023-04-09T20:12:18.290695Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model int8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: 0.00392156862745098 \n",
      "z: -128.0\n",
      "s: 0.09114260206035539 \n",
      "z: -128.0\n",
      "s: 0.26033223470052086 \n",
      "z: 8.0\n"
     ]
    }
   ],
   "source": [
    "int8_s_w1, int8_z_w1, int8_w1 = weight_arr_quan(model.layers[0].get_weights()[0], -127, 127)\n",
    "int8_s_i1, int8_z_i1 = activation_scale_zero_point(train_images_float32, 256)\n",
    "int8_s_b1, int8_z_b1, int8_b1 = bias_arr_quan(model.layers[0].get_weights()[1], int8_s_w1, int8_s_i1)\n",
    "\n",
    "int8_s_w2, int8_z_w2, int8_w2 = weight_arr_quan(model.layers[1].get_weights()[0], -127, 127)\n",
    "int8_s_i2, int8_z_i2 = activation_scale_zero_point(intermediate_output_float32, 256)\n",
    "int8_s_b2, int8_z_b2, int8_b2 = bias_arr_quan(model.layers[1].get_weights()[1], int8_s_w2, int8_s_i2)\n",
    "\n",
    "int8_s_o1, int8_z_o1 = int8_s_i2, int8_z_i2\n",
    "\n",
    "int8_s_o2, int8_z_o2 = activation_scale_zero_point(outputs_float32, 256)\n",
    "\n",
    "\n",
    "model_int8 = Module()\n",
    "model_int8.add_module(FullyConnected(int8_w1.T, int8_b1, int8_s_w1, int8_s_i1, int8_s_o1, int8_z_i1, int8_z_o1, -128, 127), 'l1')\n",
    "model_int8.add_module(FullyConnected(int8_w2.T, int8_b2, int8_s_w2, int8_s_i2, int8_s_o2, int8_z_i2, int8_z_o2, -128, 127), 'l2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T20:12:18.290695Z",
     "end_time": "2023-04-09T20:12:18.402433Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model int4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: 0.06666666666666667 \n",
      "z: -8.0\n",
      "s: 1.5494242350260417 \n",
      "z: -8.0\n",
      "s: 4.425647989908854 \n",
      "z: 0.0\n"
     ]
    }
   ],
   "source": [
    "int4_s_w1, int4_z_w1, int4_w1 = weight_arr_quan(model.layers[0].get_weights()[0], -7, 7)\n",
    "int4_s_i1, int4_z_i1 = activation_scale_zero_point(train_images_float32, 16)\n",
    "int4_s_b1, int4_z_b1, int4_b1 = bias_arr_quan(model.layers[0].get_weights()[1], int4_s_w1, int4_s_i1)\n",
    "\n",
    "int4_s_w2, int4_z_w2, int4_w2 = weight_arr_quan(model.layers[1].get_weights()[0], -7, 7)\n",
    "int4_s_i2, int4_z_i2 = activation_scale_zero_point(intermediate_output_float32, 16)\n",
    "int4_s_b2, int4_z_b2, int4_b2 = bias_arr_quan(model.layers[1].get_weights()[1], int4_s_w2, int4_s_i2)\n",
    "\n",
    "int4_s_o1, int4_z_o1 = int4_s_i2, int4_z_i2\n",
    "\n",
    "int4_s_o2, int4_z_o2 = activation_scale_zero_point(outputs_float32, 16)\n",
    "\n",
    "\n",
    "model_int4 = Module()\n",
    "model_int4.add_module(FullyConnected(int4_w1.T, int4_b1, int4_s_w1, int4_s_i1, int4_s_o1, int4_z_i1, int4_z_o1, -8, 7), 'l1')\n",
    "model_int4.add_module(FullyConnected(int4_w2.T, int4_b2, int4_s_w2, int4_s_i2, int4_s_o2, int4_z_i2, int4_z_o2, -8, 7), 'l2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T20:12:18.402433Z",
     "end_time": "2023-04-09T20:12:18.500970Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model int2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: 0.3333333333333333 \n",
      "z: -2.0\n",
      "s: 7.747121175130208 \n",
      "z: -2.0\n",
      "s: 22.12823994954427 \n",
      "z: 0.0\n"
     ]
    }
   ],
   "source": [
    "int2_s_w1, int2_z_w1, int2_w1 = weight_arr_quan(model.layers[0].get_weights()[0], -1, 1)\n",
    "int2_s_i1, int2_z_i1 = activation_scale_zero_point(train_images_float32, 4)\n",
    "int2_s_b1, int2_z_b1, int2_b1 = bias_arr_quan(model.layers[0].get_weights()[1], int2_s_w1, int2_s_i1)\n",
    "\n",
    "int2_s_w2, int2_z_w2, int2_w2 = weight_arr_quan(model.layers[1].get_weights()[0], -1, 1)\n",
    "int2_s_i2, int2_z_i2 = activation_scale_zero_point(intermediate_output_float32, 4)\n",
    "int2_s_b2, int2_z_b2, int2_b2 = bias_arr_quan(model.layers[1].get_weights()[1], int2_s_w2, int2_s_i2)\n",
    "\n",
    "int2_s_o1, int2_z_o1 = int2_s_i2, int2_z_i2\n",
    "\n",
    "int2_s_o2, int2_z_o2 = activation_scale_zero_point(outputs_float32, 4)\n",
    "\n",
    "\n",
    "model_int2 = Module()\n",
    "model_int2.add_module(FullyConnected(int2_w1.T, int2_b1, int2_s_w1, int2_s_i1, int2_s_o1, int2_z_i1, int2_z_o1, -2, 1), 'l1')\n",
    "model_int2.add_module(FullyConnected(int2_w2.T, int2_b2, int2_s_w2, int2_s_i2, int2_s_o2, int2_z_i2, int2_z_o2, -2, 1), 'l2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T20:12:18.500970Z",
     "end_time": "2023-04-09T20:12:18.610787Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare TFLite_int8, int8, int4 and int2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Initialize the interpreter\n",
    "import pathlib\n",
    "\n",
    "tflite_file = pathlib.Path('.\\models\\mnist_int8_tflite_model.tflite')\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "def run_tflite_model(interpreter, input):\n",
    "\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "\n",
    "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "    test_image = input / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "\n",
    "\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_index)\n",
    "\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T20:12:18.610787Z",
     "end_time": "2023-04-09T20:12:18.658088Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done  1000\n",
      "done  2000\n",
      "done  3000\n",
      "done  4000\n",
      "done  5000\n",
      "done  6000\n",
      "done  7000\n",
      "done  8000\n",
      "done  9000\n",
      "Mistake in output: 0.0002\n",
      "Mistake in value: 2e-05\n",
      "\n",
      "313/313 [==============================] - 0s 748us/step - loss: 0.1665 - accuracy: 0.9532\n",
      "Accuracy float32:  0.9531999826431274\n",
      "Accuracy int8 tf:  0.9535\n",
      "Accuracy int8   :  0.9535\n",
      "Accuracy int4   :  0.8842\n",
      "Accuracy int2   :  0.098\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dif = np.array([0])\n",
    "correct_int8 = 0\n",
    "correct_int4 = 0\n",
    "correct_int2 = 0\n",
    "correct_int8_tf = 0\n",
    "\n",
    "mistakes_int8 = np.array([])\n",
    "mistakes_int4 = np.array([])\n",
    "mistakes_int2 = np.array([])\n",
    "mistakes_int8_tf = np.array([])\n",
    "\n",
    "for i in range(eva_images_float32.shape[0]):\n",
    "\n",
    "    if i % 1000 == 0 and i != 0:\n",
    "        print(\"done \", i)\n",
    "\n",
    "    input_int8_tf = eva_images_float32[i]\n",
    "\n",
    "    input_int8 = eva_images_float32[i]\n",
    "    input_int8 = input_int8 / int8_s_i1 + int8_z_i1\n",
    "    input_int8 = np.expand_dims(input_int8, axis=0).astype(np.int8)\n",
    "\n",
    "    input_int4 = eva_images_float32[i]\n",
    "    input_int4 = input_int4 / int4_s_i1 + int4_z_i1\n",
    "    input_int4 = np.expand_dims(input_int4, axis=0).astype(np.int8)\n",
    "\n",
    "    input_int2 = eva_images_float32[i]\n",
    "    input_int2 = input_int2 / int2_s_i1 + int2_z_i1\n",
    "    input_int2 = np.expand_dims(input_int2, axis=0).astype(np.int8)\n",
    "\n",
    "\n",
    "    output_model_int8 = model_int8.forward(input_int8)\n",
    "    output_model_int4 = model_int4.forward(input_int4)\n",
    "    output_model_int2 = model_int2.forward(input_int2)\n",
    "    output_model_int8_tf = run_tflite_model(interpreter, input_int8_tf)\n",
    "\n",
    "    dif[0] += np.sum(np.abs(output_model_int8 - output_model_int8_tf))\n",
    "\n",
    "    answer_int8 = np.argmax(output_model_int8)\n",
    "    answer_int4 = np.argmax(output_model_int4)\n",
    "    answer_int2 = np.argmax(output_model_int2)\n",
    "    answer_int8_tf = np.argmax(output_model_int8_tf)\n",
    "\n",
    "    if answer_int8 == eva_labels[i]:\n",
    "        correct_int8 += 1\n",
    "    else:\n",
    "        mistakes_int8 = np.append(mistakes_int8, i)\n",
    "\n",
    "    if answer_int4 == eva_labels[i]:\n",
    "        correct_int4 += 1\n",
    "    else:\n",
    "        mistakes_int4 = np.append(mistakes_int4, i)\n",
    "\n",
    "    if answer_int2 == eva_labels[i]:\n",
    "        correct_int2 += 1\n",
    "    else:\n",
    "        mistakes_int2 = np.append(mistakes_int2, i)\n",
    "\n",
    "    if answer_int8_tf == eva_labels[i]:\n",
    "        correct_int8_tf += 1\n",
    "    else:\n",
    "        mistakes_int8_tf = np.append(mistakes_int8_tf, i)\n",
    "\n",
    "\n",
    "# np.save('/array_dif_int8tf_int8_my-weights-scales-zpoints.npy', dif)\n",
    "# np.save('/mistakes_int8.npy', mistakes_int8)\n",
    "# np.save('/mistakes_int4.npy', mistakes_int4)\n",
    "# np.save('/mistakes_int2.npy', mistakes_int2)\n",
    "# np.save('/mistakes_int8_tf.npy', mistakes_int8_tf)\n",
    "\n",
    "mistake_output = np.sum(dif) / eva_images_float32.shape[0]\n",
    "mistake_value = mistake_output / 10\n",
    "\n",
    "print(f'Mistake in output: {mistake_output}')\n",
    "print(f'Mistake in value: {mistake_value}\\n')\n",
    "\n",
    "print('Accuracy float32: ', model.evaluate(eva_images_float32, eva_labels)[1])\n",
    "print('Accuracy int8 tf: ', correct_int8_tf / eva_images_float32.shape[0])\n",
    "print('Accuracy int8   : ', correct_int8 / eva_images_float32.shape[0])\n",
    "print('Accuracy int4   : ', correct_int4 / eva_images_float32.shape[0])\n",
    "print('Accuracy int2   : ', correct_int2 / eva_images_float32.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T20:12:18.626415Z",
     "end_time": "2023-04-09T20:24:47.752414Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 736us/step - loss: 0.1665 - accuracy: 0.9532\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.1665320098400116, 0.9531999826431274]"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(eva_images_float32, eva_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T23:56:54.730578Z",
     "end_time": "2023-04-07T23:56:55.143832Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dif = np.load('mistakes_layer2_neurons20-10/array_dif_int8tf_int8my-weights-scales-zpoints.npy')\n",
    "mistake_output = np.sum(dif) / eva_images_float32.shape[0]\n",
    "mistake_value = mistake_output / 10\n",
    "\n",
    "print(f'Mistake in output: {mistake_output}')\n",
    "print(f'Mistake in value: {mistake_value}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T23:15:21.630261Z",
     "end_time": "2023-04-03T23:15:21.686214Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8.  63. 115. 149. 158. 217. 233. 241. 247. 259.]\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:06:36.281119Z",
     "end_time": "2023-04-08T00:06:36.285625Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bigger nn model float32 500-500-500-10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.1981 - accuracy: 0.9405 - val_loss: 0.1094 - val_accuracy: 0.9659\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0843 - accuracy: 0.9739 - val_loss: 0.0786 - val_accuracy: 0.9772\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0612 - accuracy: 0.9813 - val_loss: 0.0941 - val_accuracy: 0.9736\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.0465 - accuracy: 0.9857 - val_loss: 0.1165 - val_accuracy: 0.9695\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0382 - accuracy: 0.9883 - val_loss: 0.0910 - val_accuracy: 0.9740\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 0.0922 - val_accuracy: 0.9758\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 0.0808 - val_accuracy: 0.9822\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.0856 - val_accuracy: 0.9803\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.1112 - val_accuracy: 0.9754\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.0824 - val_accuracy: 0.9813\n",
      "1875/1875 [==============================] - 2s 967us/step\n",
      "1875/1875 [==============================] - 3s 1ms/step\n",
      "1875/1875 [==============================] - 3s 2ms/step\n",
      "1875/1875 [==============================] - 3s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(500, activation='relu', input_dim=input_size),\n",
    "        tf.keras.layers.Dense(500, activation='relu'),\n",
    "        tf.keras.layers.Dense(500, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "model.fit(\n",
    "    train_images_float32,\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_data=(eva_images_float32, eva_labels)\n",
    ")\n",
    "\n",
    "# Define a new model that outputs the intermediate layer\n",
    "intermediate_model_1 = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
    "intermediate_model_2 = tf.keras.Model(inputs=model.input, outputs=model.layers[1].output)\n",
    "intermediate_model_3 = tf.keras.Model(inputs=model.input, outputs=model.layers[2].output)\n",
    "\n",
    "# Get the intermediate output for the entire input dataset\n",
    "intermediate_output_1_float32 = intermediate_model_1.predict(train_images_float32)\n",
    "intermediate_output_2_float32 = intermediate_model_2.predict(train_images_float32)\n",
    "intermediate_output_3_float32 = intermediate_model_3.predict(train_images_float32)\n",
    "\n",
    "outputs_float32 = model.predict(train_images_float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T11:43:23.982338Z",
     "end_time": "2023-04-08T11:44:39.072065Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float weights saved to:  models\\mnist_float_nn_tf_layers4_neurons_500-500-500-10\\mnist_float_weights\n"
     ]
    }
   ],
   "source": [
    "tflite_models_dir = pathlib.Path(\"models\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "float_weights_path = r\"./models/mnist_float_nn_tf_layers4_neurons_500-500-500-10/mnist_float_weights\"\n",
    "\n",
    "# Save the model:\n",
    "float_weights_model_file = tflite_models_dir / \"mnist_float_nn_tf_layers4_neurons_500-500-500-10/mnist_float_weights\"\n",
    "float_weights_model_file_index = tflite_models_dir / \"mnist_float_nn_tf_layers4_neurons_500-500-500-10/mnist_float_weights.index\"\n",
    "if not float_weights_model_file_index.is_file():\n",
    "    model.save_weights(float_weights_model_file)\n",
    "    print(\"Float weights saved to: \", float_weights_model_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T11:57:34.237122Z",
     "end_time": "2023-04-08T11:57:34.313040Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x24b046b7508>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.load_weights(float_weights_model_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T11:58:30.762136Z",
     "end_time": "2023-04-08T11:58:30.863318Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bigger nn model int8 tf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Patrik\\AppData\\Local\\Temp\\tmpwt6t4nzt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dp\\dp\\code\\openvino_notebooks_py37\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in train_images_float32:\n",
    "        yield [input_value]\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Set the input and output tensors to int8\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T11:58:45.471782Z",
     "end_time": "2023-04-08T11:58:51.818577Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to:  models\\mnist_int8_tflite_model_layers4_neurons500-500-500-10.tflite\n",
      "Serving 'models/mnist_int8_tflite_model_layers4_neurons500-500-500-10.tflite' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": "('localhost', 8080)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_models_dir = pathlib.Path(\"models\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "model_path = r\"models/mnist_int8_tflite_model_layers4_neurons500-500-500-10\"\n",
    "\n",
    "# Save the model:\n",
    "int8_tflite_model_file = tflite_models_dir / \"mnist_int8_tflite_model_layers4_neurons500-500-500-10.tflite\"\n",
    "if not int8_tflite_model_file.is_file():\n",
    "    int8_tflite_model_file.write_bytes(tflite_model_quant)\n",
    "    print(\"Model saved to: \", int8_tflite_model_file)\n",
    "\n",
    "netron.start(model_path + r'.tflite')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T11:59:00.431932Z",
     "end_time": "2023-04-08T11:59:00.521713Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "tflite_file = pathlib.Path('.\\models\\mnist_int8_tflite_model_layers4_neurons500-500-500-10.tflite')\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "interpreter.allocate_tensors()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T11:59:21.651776Z",
     "end_time": "2023-04-08T11:59:21.662077Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bigger nn model int8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: 0.00392156862745098 \n",
      "z: -128.0\n",
      "s: 0.03778261296889361 \n",
      "z: -128.0\n",
      "s: 0.0717007506127451 \n",
      "z: -128.0\n",
      "s: 0.15143588196997548 \n",
      "z: -128.0\n",
      "s: 0.6677820542279411 \n",
      "z: 10.0\n"
     ]
    }
   ],
   "source": [
    "int8_s_w1, int8_z_w1, int8_w1 = weight_arr_quan(model.layers[0].get_weights()[0], -127, 127)\n",
    "int8_s_i1, int8_z_i1 = activation_scale_zero_point(train_images_float32, 256)\n",
    "int8_s_b1, int8_z_b1, int8_b1 = bias_arr_quan(model.layers[0].get_weights()[1], int8_s_w1, int8_s_i1)\n",
    "\n",
    "int8_s_w2, int8_z_w2, int8_w2 = weight_arr_quan(model.layers[1].get_weights()[0], -127, 127)\n",
    "int8_s_i2, int8_z_i2 = activation_scale_zero_point(intermediate_output_1_float32, 256)\n",
    "int8_s_b2, int8_z_b2, int8_b2 = bias_arr_quan(model.layers[1].get_weights()[1], int8_s_w2, int8_s_i2)\n",
    "\n",
    "int8_s_w3, int8_z_w3, int8_w3 = weight_arr_quan(model.layers[2].get_weights()[0], -127, 127)\n",
    "int8_s_i3, int8_z_i3 = activation_scale_zero_point(intermediate_output_2_float32, 256)\n",
    "int8_s_b3, int8_z_b3, int8_b3 = bias_arr_quan(model.layers[2].get_weights()[1], int8_s_w3, int8_s_i3)\n",
    "\n",
    "int8_s_w4, int8_z_w4, int8_w4 = weight_arr_quan(model.layers[3].get_weights()[0], -127, 127)\n",
    "int8_s_i4, int8_z_i4 = activation_scale_zero_point(intermediate_output_3_float32, 256)\n",
    "int8_s_b4, int8_z_b4, int8_b4 = bias_arr_quan(model.layers[3].get_weights()[1], int8_s_w4, int8_s_i4)\n",
    "\n",
    "int8_s_o1, int8_z_o1 = int8_s_i2, int8_z_i2\n",
    "int8_s_o2, int8_z_o2 = int8_s_i3, int8_z_i3\n",
    "int8_s_o3, int8_z_o3 = int8_s_i4, int8_z_i4\n",
    "int8_s_o4, int8_z_o4 = activation_scale_zero_point(outputs_float32, 256)\n",
    "\n",
    "model_int8 = Module()\n",
    "model_int8.add_module(FullyConnected(int8_w1.T, int8_b1, int8_s_w1, int8_s_i1, int8_s_o1, int8_z_i1, int8_z_o1, -128, 127), 'l1')\n",
    "model_int8.add_module(FullyConnected(int8_w2.T, int8_b2, int8_s_w2, int8_s_i2, int8_s_o2, int8_z_i2, int8_z_o2, -128, 127), 'l2')\n",
    "model_int8.add_module(FullyConnected(int8_w3.T, int8_b3, int8_s_w3, int8_s_i3, int8_s_o3, int8_z_i3, int8_z_o3, -128, 127), 'l3')\n",
    "model_int8.add_module(FullyConnected(int8_w4.T, int8_b4, int8_s_w4, int8_s_i4, int8_s_o4, int8_z_i4, int8_z_o4, -128, 127), 'l4')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T12:01:05.463866Z",
     "end_time": "2023-04-08T12:01:09.419578Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bigger nn model int4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: 0.06666666666666667 \n",
      "z: -8.0\n",
      "s: 0.6423044204711914 \n",
      "z: -8.0\n",
      "s: 1.2189127604166667 \n",
      "z: -8.0\n",
      "s: 2.574409993489583 \n",
      "z: -8.0\n",
      "s: 11.352294921875 \n",
      "z: 0.0\n"
     ]
    }
   ],
   "source": [
    "int4_s_w1, int4_z_w1, int4_w1 = weight_arr_quan(model.layers[0].get_weights()[0], -7, 7)\n",
    "int4_s_i1, int4_z_i1 = activation_scale_zero_point(train_images_float32, 16)\n",
    "int4_s_b1, int4_z_b1, int4_b1 = bias_arr_quan(model.layers[0].get_weights()[1], int4_s_w1, int4_s_i1)\n",
    "\n",
    "int4_s_w2, int4_z_w2, int4_w2 = weight_arr_quan(model.layers[1].get_weights()[0], -7, 7)\n",
    "int4_s_i2, int4_z_i2 = activation_scale_zero_point(intermediate_output_1_float32, 16)\n",
    "int4_s_b2, int4_z_b2, int4_b2 = bias_arr_quan(model.layers[1].get_weights()[1], int4_s_w2, int4_s_i2)\n",
    "\n",
    "int4_s_w3, int4_z_w3, int4_w3 = weight_arr_quan(model.layers[2].get_weights()[0], -7, 7)\n",
    "int4_s_i3, int4_z_i3 = activation_scale_zero_point(intermediate_output_2_float32, 16)\n",
    "int4_s_b3, int4_z_b3, int4_b3 = bias_arr_quan(model.layers[2].get_weights()[1], int4_s_w3, int4_s_i3)\n",
    "\n",
    "int4_s_w4, int4_z_w4, int4_w4 = weight_arr_quan(model.layers[3].get_weights()[0], -7, 7)\n",
    "int4_s_i4, int4_z_i4 = activation_scale_zero_point(intermediate_output_3_float32, 16)\n",
    "int4_s_b4, int4_z_b4, int4_b4 = bias_arr_quan(model.layers[3].get_weights()[1], int4_s_w4, int4_s_i4)\n",
    "\n",
    "int4_s_o1, int4_z_o1 = int4_s_i2, int4_z_i2\n",
    "int4_s_o2, int4_z_o2 = int4_s_i3, int4_z_i3\n",
    "int4_s_o3, int4_z_o3 = int4_s_i4, int4_z_i4\n",
    "int4_s_o4, int4_z_o4 = activation_scale_zero_point(outputs_float32, 16)\n",
    "\n",
    "model_int4 = Module()\n",
    "model_int4.add_module(FullyConnected(int4_w1.T, int4_b1, int4_s_w1, int4_s_i1, int4_s_o1, int4_z_i1, int4_z_o1, -8, 7), 'l1')\n",
    "model_int4.add_module(FullyConnected(int4_w2.T, int4_b2, int4_s_w2, int4_s_i2, int4_s_o2, int4_z_i2, int4_z_o2, -8, 7), 'l2')\n",
    "model_int4.add_module(FullyConnected(int4_w3.T, int4_b3, int4_s_w3, int4_s_i3, int4_s_o3, int4_z_i3, int4_z_o3, -8, 7), 'l3')\n",
    "model_int4.add_module(FullyConnected(int4_w4.T, int4_b4, int4_s_w4, int4_s_i4, int4_s_o4, int4_z_i4, int4_z_o4, -8, 7), 'l4')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T12:03:50.333881Z",
     "end_time": "2023-04-08T12:03:54.491656Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bigger nn model int2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: 0.3333333333333333 \n",
      "z: -2.0\n",
      "s: 3.211522102355957 \n",
      "z: -2.0\n",
      "s: 6.094563802083333 \n",
      "z: -2.0\n",
      "s: 12.872049967447916 \n",
      "z: -2.0\n",
      "s: 56.761474609375 \n",
      "z: 0.0\n"
     ]
    }
   ],
   "source": [
    "int2_s_w1, int2_z_w1, int2_w1 = weight_arr_quan(model.layers[0].get_weights()[0], -1, 1)\n",
    "int2_s_i1, int2_z_i1 = activation_scale_zero_point(train_images_float32, 4)\n",
    "int2_s_b1, int2_z_b1, int2_b1 = bias_arr_quan(model.layers[0].get_weights()[1], int2_s_w1, int2_s_i1)\n",
    "\n",
    "int2_s_w2, int2_z_w2, int2_w2 = weight_arr_quan(model.layers[1].get_weights()[0], -1, 1)\n",
    "int2_s_i2, int2_z_i2 = activation_scale_zero_point(intermediate_output_1_float32, 4)\n",
    "int2_s_b2, int2_z_b2, int2_b2 = bias_arr_quan(model.layers[1].get_weights()[1], int2_s_w2, int2_s_i2)\n",
    "\n",
    "int2_s_w3, int2_z_w3, int2_w3 = weight_arr_quan(model.layers[2].get_weights()[0], -1, 1)\n",
    "int2_s_i3, int2_z_i3 = activation_scale_zero_point(intermediate_output_2_float32, 4)\n",
    "int2_s_b3, int2_z_b3, int2_b3 = bias_arr_quan(model.layers[2].get_weights()[1], int2_s_w3, int2_s_i3)\n",
    "\n",
    "int2_s_w4, int2_z_w4, int2_w4 = weight_arr_quan(model.layers[3].get_weights()[0], -1, 1)\n",
    "int2_s_i4, int2_z_i4 = activation_scale_zero_point(intermediate_output_3_float32, 4)\n",
    "int2_s_b4, int2_z_b4, int2_b4 = bias_arr_quan(model.layers[3].get_weights()[1], int2_s_w4, int2_s_i4)\n",
    "\n",
    "int2_s_o1, int2_z_o1 = int2_s_i2, int2_z_i2\n",
    "int2_s_o2, int2_z_o2 = int2_s_i3, int2_z_i3\n",
    "int2_s_o3, int2_z_o3 = int2_s_i4, int2_z_i4\n",
    "int2_s_o4, int2_z_o4 = activation_scale_zero_point(outputs_float32, 4)\n",
    "\n",
    "model_int2 = Module()\n",
    "model_int2.add_module(FullyConnected(int2_w1.T, int2_b1, int2_s_w1, int2_s_i1, int2_s_o1, int2_z_i1, int2_z_o1, -2, 1), 'l1')\n",
    "model_int2.add_module(FullyConnected(int2_w2.T, int2_b2, int2_s_w2, int2_s_i2, int2_s_o2, int2_z_i2, int2_z_o2, -2, 1), 'l2')\n",
    "model_int2.add_module(FullyConnected(int2_w3.T, int2_b3, int2_s_w3, int2_s_i3, int2_s_o3, int2_z_i3, int2_z_o3, -2, 1), 'l3')\n",
    "model_int2.add_module(FullyConnected(int2_w4.T, int2_b4, int2_s_w4, int2_s_i4, int2_s_o4, int2_z_i4, int2_z_o4, -2, 1), 'l4')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T12:03:57.791951Z",
     "end_time": "2023-04-08T12:04:02.925757Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistake in output: 0.0\n",
      "Mistake in value: 0.0\n",
      "\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0824 - accuracy: 0.9813\n",
      "Accuracy float32:  0.9812999963760376\n",
      "Accuracy int8 tf:  0.9802\n",
      "Accuracy int8   :  0.9802\n",
      "Accuracy int4   :  0.9483\n",
      "Accuracy int2   :  0.098\n"
     ]
    }
   ],
   "source": [
    "dif = np.array([0])\n",
    "correct_int8 = 0\n",
    "correct_int4 = 0\n",
    "correct_int2 = 0\n",
    "correct_int8_tf = 0\n",
    "\n",
    "mistakes_int8 = np.array([])\n",
    "mistakes_int4 = np.array([])\n",
    "mistakes_int2 = np.array([])\n",
    "mistakes_int8_tf = np.array([])\n",
    "\n",
    "for i in range(eva_images_float32.shape[0]):\n",
    "\n",
    "    input_int8_tf = eva_images_float32[i]\n",
    "\n",
    "    input_int8 = eva_images_float32[i]\n",
    "    input_int8 = input_int8 / int8_s_i1 + int8_z_i1\n",
    "    input_int8 = np.expand_dims(input_int8, axis=0).astype(np.int8)\n",
    "\n",
    "    input_int4 = eva_images_float32[i]\n",
    "    input_int4 = input_int4 / int4_s_i1 + int4_z_i1\n",
    "    input_int4 = np.expand_dims(input_int4, axis=0).astype(np.int8)\n",
    "\n",
    "    input_int2 = eva_images_float32[i]\n",
    "    input_int2 = input_int2 / int2_s_i1 + int2_z_i1\n",
    "    input_int2 = np.expand_dims(input_int2, axis=0).astype(np.int8)\n",
    "\n",
    "\n",
    "    output_model_int8 = model_int8.forward(input_int8)\n",
    "    output_model_int4 = model_int4.forward(input_int4)\n",
    "    output_model_int2 = model_int2.forward(input_int2)\n",
    "    output_model_int8_tf = run_tflite_model(interpreter, input_int8_tf)\n",
    "\n",
    "    dif[0] += np.sum(np.abs(output_model_int8 - output_model_int8_tf))\n",
    "\n",
    "    answer_int8 = np.argmax(output_model_int8)\n",
    "    answer_int4 = np.argmax(output_model_int4)\n",
    "    answer_int2 = np.argmax(output_model_int2)\n",
    "    answer_int8_tf = np.argmax(output_model_int8_tf)\n",
    "\n",
    "    if answer_int8 == eva_labels[i]:\n",
    "        correct_int8 += 1\n",
    "    else:\n",
    "        mistakes_int8 = np.append(mistakes_int8, i)\n",
    "\n",
    "    if answer_int4 == eva_labels[i]:\n",
    "        correct_int4 += 1\n",
    "    else:\n",
    "        mistakes_int4 = np.append(mistakes_int4, i)\n",
    "\n",
    "    if answer_int2 == eva_labels[i]:\n",
    "        correct_int2 += 1\n",
    "    else:\n",
    "        mistakes_int2 = np.append(mistakes_int2, i)\n",
    "\n",
    "    if answer_int8_tf == eva_labels[i]:\n",
    "        correct_int8_tf += 1\n",
    "    else:\n",
    "        mistakes_int8_tf = np.append(mistakes_int8_tf, i)\n",
    "\n",
    "\n",
    "np.save('mistakes_layers4_neurons500-500-500-10/array_dif_int8tf_int8_my-weights-scales-zpoints.npy', dif)\n",
    "np.save('mistakes_layers4_neurons500-500-500-10/mistakes_int8.npy', mistakes_int8)\n",
    "np.save('mistakes_layers4_neurons500-500-500-10/mistakes_int4.npy', mistakes_int4)\n",
    "np.save('mistakes_layers4_neurons500-500-500-10/mistakes_int2.npy', mistakes_int2)\n",
    "np.save('mistakes_layers4_neurons500-500-500-10/mistakes_int8_tf.npy', mistakes_int8_tf)\n",
    "\n",
    "mistake_output = np.sum(dif) / eva_images_float32.shape[0]\n",
    "mistake_value = mistake_output / 10\n",
    "\n",
    "print(f'Mistake in output: {mistake_output}')\n",
    "print(f'Mistake in value: {mistake_value}\\n')\n",
    "\n",
    "print('Accuracy float32: ', model.evaluate(eva_images_float32, eva_labels)[1])\n",
    "print('Accuracy int8 tf: ', correct_int8_tf / eva_images_float32.shape[0])\n",
    "print('Accuracy int8   : ', correct_int8 / eva_images_float32.shape[0])\n",
    "print('Accuracy int4   : ', correct_int4 / eva_images_float32.shape[0])\n",
    "print('Accuracy int2   : ', correct_int2 / eva_images_float32.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T12:04:35.343338Z",
     "end_time": "2023-04-09T00:47:21.103258Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
