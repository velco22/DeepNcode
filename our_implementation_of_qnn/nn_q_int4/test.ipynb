{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This is designed for inference calculation only"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.DEBUG)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import netron"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-10T14:04:03.876777Z",
     "end_time": "2023-04-10T14:04:08.867503Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation mnist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size: 28, input_size: 784\n",
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (eva_images, eva_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images_float32_28x28 = train_images.astype(np.float32) / 255.0\n",
    "eva_images_float32_28x28 = eva_images.astype(np.float32) / 255.0\n",
    "\n",
    "# Normalize the input image so that each pixel value is between -128 and 127.\n",
    "train_images_int8 = np.int8(train_images.astype(np.float32) - 128.0)\n",
    "eva_images_int8 = np.int8(eva_images.astype(np.float32) - 128.0)\n",
    "\n",
    "# image dimensions (assumed square)\n",
    "image_size = train_images_float32_28x28.shape[1]\n",
    "input_size = image_size * image_size\n",
    "print(f'image_size: {image_size}, input_size: {input_size}')\n",
    "\n",
    "#reshape data to fit model\n",
    "train_images_float32 = np.reshape(train_images_float32_28x28, [-1, input_size])\n",
    "eva_images_float32 = np.reshape(eva_images_float32_28x28, [-1, input_size])\n",
    "\n",
    "print(train_images_float32.shape)\n",
    "print(eva_images_float32.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-10T14:04:08.867503Z",
     "end_time": "2023-04-10T14:04:09.247154Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Manual calculation of Inference for quantized nn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self.modules = OrderedDict()\n",
    "\n",
    "    def add_module(self, module, name:str):\n",
    "        self.modules[name] = module\n",
    "\n",
    "    def forward(self, input) -> np.ndarray:\n",
    "        for module in self.modules:\n",
    "            # print(f\"module: {module}\")\n",
    "            input = self.modules[module].forward(input)\n",
    "\n",
    "        return input"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:17:43.137522Z",
     "end_time": "2023-04-09T19:17:43.184996Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#   FullyConnected class\n",
    "#------------------------------------------------------------------------------\n",
    "class FullyConnected(Module):\n",
    "    def __init__(self, w, b, s_w, s_i, s_o, z_i, z_o, min_T, max_T):\n",
    "        super(FullyConnected, self).__init__()\n",
    "        self.W = w\n",
    "        self.b = b\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.m = s_i * s_w / s_o\n",
    "        self.s_b = s_i * s_w\n",
    "        self.min_T = min_T\n",
    "        self.max_T = max_T\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        output_int8 = np.zeros((input.shape[0], self.W.shape[1]), dtype=np.int8)\n",
    "        output = np.zeros((input.shape[0], self.W.shape[1]), dtype=np.int32)\n",
    "        a2 = np.zeros((self.W.shape[1]), dtype=np.int32)\n",
    "\n",
    "        for i in range(input.shape[0]):\n",
    "            for k in range(self.W.shape[1]):\n",
    "                for j in range(input.shape[1]):\n",
    "                    a2[k] += np.int32(self.W[j][k])\n",
    "                    output[i][k] += np.int32(input[i][j]) * np.int32(self.W[j][k])\n",
    "\n",
    "                    # print(f'i = {input[i][j]}, W = {self.W[j][k]}, output_32 = {output[i][k]}, a2={a2[k]}')\n",
    "\n",
    "                # print('-----------------')\n",
    "                # print(f'z_o = {self.z_o}, m = {self.m}, o = {output[i][k]}, b = {self.b[k]}, a2 = {a2[k]}, z_i = {self.z_i}, zia2: {-self.z_i*a2[k]}')\n",
    "                # print(f'output_before_saturate_cast = ',np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k]))\n",
    "\n",
    "                # output_int8[i][k] = tf.dtypes.saturate_cast(np.round(np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k])), tf.int8)\n",
    "\n",
    "                ourput_value = np.round(np.int32(self.z_o) + self.m * (-(np.int32(self.z_i)*a2[k]) + output[i][k] + self.b[k]))\n",
    "\n",
    "                if ourput_value > self.max_T:\n",
    "                    output_int8[i][k] = np.int8(self.max_T)\n",
    "                elif ourput_value < self.min_T:\n",
    "                    output_int8[i][k] = np.int8(self.min_T)\n",
    "                else:\n",
    "                    output_int8[i][k] = np.int8(ourput_value)\n",
    "\n",
    "                # print('output_int8: ', output_int8[i][k])\n",
    "                # print('-----------------')\n",
    "\n",
    "        # print(f'input: {input} \\noutput: {output_int8}\\n-----------------\\n-----------------')\n",
    "        # print(f'input: {input.dtype} \\noutput2: {output_int8.dtype}\\n-----------------')\n",
    "\n",
    "        return output_int8\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#   Quantize class\n",
    "#------------------------------------------------------------------------------\n",
    "class Quantize(Module):\n",
    "    def __init__(self, s, z_i, z_o, d_type):\n",
    "        super(Quantize, self).__init__()\n",
    "        self.z_i = z_i\n",
    "        self.z_o = z_o\n",
    "        self.s = s\n",
    "        self.d_type = d_type\n",
    "\n",
    "        # print(f'Quantize: z_i: {self.z_i} z_o: {self.z_o} s: {self.s} d_type: {self.d_type}')\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        # converts from int8 to uint8 and vice versa\n",
    "        if self.d_type is np.int8:\n",
    "            arr_q = (input + 128).astype(np.uint8)\n",
    "        elif self.d_type is np.uint8:\n",
    "            arr_q = (input - 128).astype(np.int8)\n",
    "        else:\n",
    "            raise ValueError(f'input type is not supported: {input.dtype}')\n",
    "\n",
    "        # print(f'input: {input} \\noutput: {arr_q}\\n-----------------\\n-----------------')\n",
    "        # print(f'input: {input.dtype} \\noutput: {arr_q.dtype}\\n-----------------')\n",
    "\n",
    "        return arr_q\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:17:43.153682Z",
     "end_time": "2023-04-09T19:17:43.200577Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Calculation of a, b parameters\n",
    "\n",
    "def calculation_a_b(input_array):\n",
    "    return np.min(input_array), np.max(input_array)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Weight quantization\n",
    "\n",
    "def weight_scaling_factor(a, b, min_T, max_T):\n",
    "    s_a = a / min_T\n",
    "    s_b = b / max_T\n",
    "\n",
    "    if s_a > s_b:\n",
    "        return s_a, a, max_T * s_a\n",
    "    else:\n",
    "        return s_b, min_T * s_b, b\n",
    "\n",
    "def clamp(r,a,b):\n",
    "    return min(max(r, a), b)\n",
    "\n",
    "def weight_quan(r, a, b, min_T, s):\n",
    "\n",
    "    q_value = np.round((clamp(r,a,b) - a) / s) + min_T\n",
    "\n",
    "    # print(f'q_value: {q_value}')\n",
    "\n",
    "    z = 0\n",
    "    r = s * (q_value - z)\n",
    "\n",
    "    # print(f'r: {r}')\n",
    "\n",
    "    return q_value\n",
    "\n",
    "def weight_arr_quan(input_arr, min_T, max_T):\n",
    "\n",
    "    a, b = calculation_a_b(input_arr)\n",
    "    s, a, b = weight_scaling_factor(a, b, min_T, max_T)\n",
    "\n",
    "    out_arr = np.zeros(input_arr.shape, dtype=np.int8).T\n",
    "\n",
    "    for i in range(input_arr.shape[0]):\n",
    "        for j in range(input_arr.shape[1]):\n",
    "            out_arr[j][i] = weight_quan(input_arr[i][j], a, b, min_T, s)\n",
    "\n",
    "    return s, 0, out_arr\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Activation quantization\n",
    "\n",
    "def activation_scaling_factor(a, b, n):\n",
    "   return (b - a) / (n - 1)\n",
    "\n",
    "def activation_scale_zero_point(input_array, n):\n",
    "    a, b = calculation_a_b(input_array)\n",
    "    s = activation_scaling_factor(a, b, n)\n",
    "    q_value = np.round((0 - a) / s) - n/2\n",
    "    z = q_value - (0 / s)\n",
    "\n",
    "    print(f's: {s} \\nz: {z}')\n",
    "\n",
    "    return s, z\n",
    "\n",
    "def activation_quan(r, a, b, n, s, z):\n",
    "\n",
    "    q_value = np.round((clamp(r,a,b) - a) / s) - n/2\n",
    "\n",
    "    print(f'q_value: {q_value}')\n",
    "\n",
    "    r = s * (q_value - z)\n",
    "    print(f'r: {r}')\n",
    "\n",
    "    return q_value\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Bias quantization\n",
    "\n",
    "def bias_quan(r, s_w, s_i):\n",
    "    return np.round(r / (s_i * s_w))\n",
    "\n",
    "def bias_arr_quan(arr, s_w, s_i):\n",
    "\n",
    "    arr = np.array([bias_quan(r, s_w, s_i) for r in arr], dtype=np.int32)\n",
    "    s = s_w * s_i\n",
    "\n",
    "    return s, 0, arr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:17:43.169320Z",
     "end_time": "2023-04-09T19:17:43.200577Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model float32 TF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 561us/step\n",
      "1875/1875 [==============================] - 1s 562us/step\n"
     ]
    }
   ],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(20, activation='relu', input_dim=input_size),\n",
    "    tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "model.load_weights(r'models/mnist_float_nn_tf/mnist_float_weights')\n",
    "\n",
    "# Define a new model that outputs the intermediate layer\n",
    "intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
    "\n",
    "# Get the intermediate output for the entire input dataset\n",
    "intermediate_output_float32 = intermediate_model.predict(train_images_float32)\n",
    "\n",
    "outputs_float32 = model.predict(train_images_float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:17:43.184996Z",
     "end_time": "2023-04-09T19:17:46.051553Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model int8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: 0.00392156862745098 \n",
      "z: -128.0\n",
      "s: 0.09114260206035539 \n",
      "z: -128.0\n",
      "s: 0.26033223470052086 \n",
      "z: 8.0\n"
     ]
    }
   ],
   "source": [
    "int8_s_w1, int8_z_w1, int8_w1 = weight_arr_quan(model.layers[0].get_weights()[0], -127, 127)\n",
    "int8_s_i1, int8_z_i1 = activation_scale_zero_point(train_images_float32, 256)\n",
    "int8_s_b1, int8_z_b1, int8_b1 = bias_arr_quan(model.layers[0].get_weights()[1], int8_s_w1, int8_s_i1)\n",
    "\n",
    "int8_s_w2, int8_z_w2, int8_w2 = weight_arr_quan(model.layers[1].get_weights()[0], -127, 127)\n",
    "int8_s_i2, int8_z_i2 = activation_scale_zero_point(intermediate_output_float32, 256)\n",
    "int8_s_b2, int8_z_b2, int8_b2 = bias_arr_quan(model.layers[1].get_weights()[1], int8_s_w2, int8_s_i2)\n",
    "\n",
    "int8_s_o1, int8_z_o1 = int8_s_i2, int8_z_i2\n",
    "\n",
    "int8_s_o2, int8_z_o2 = activation_scale_zero_point(outputs_float32, 256)\n",
    "\n",
    "\n",
    "model_int8 = Module()\n",
    "model_int8.add_module(FullyConnected(int8_w1.T, int8_b1, int8_s_w1, int8_s_i1, int8_s_o1, int8_z_i1, int8_z_o1, -128, 127), 'l1')\n",
    "model_int8.add_module(FullyConnected(int8_w2.T, int8_b2, int8_s_w2, int8_s_i2, int8_s_o2, int8_z_i2, int8_z_o2, -128, 127), 'l2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:17:46.051553Z",
     "end_time": "2023-04-09T19:17:46.163298Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model int4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: 0.06666666666666667 \n",
      "z: -8.0\n",
      "s: 1.5494242350260417 \n",
      "z: -8.0\n",
      "s: 4.425647989908854 \n",
      "z: 0.0\n",
      "(784, 20)\n"
     ]
    }
   ],
   "source": [
    "int4_s_w1, int4_z_w1, int4_w1 = weight_arr_quan(model.layers[0].get_weights()[0], -7, 7)\n",
    "int4_s_i1, int4_z_i1 = activation_scale_zero_point(train_images_float32, 16)\n",
    "int4_s_b1, int4_z_b1, int4_b1 = bias_arr_quan(model.layers[0].get_weights()[1], int4_s_w1, int4_s_i1)\n",
    "\n",
    "int4_s_w2, int4_z_w2, int4_w2 = weight_arr_quan(model.layers[1].get_weights()[0], -7, 7)\n",
    "int4_s_i2, int4_z_i2 = activation_scale_zero_point(intermediate_output_float32, 16)\n",
    "int4_s_b2, int4_z_b2, int4_b2 = bias_arr_quan(model.layers[1].get_weights()[1], int4_s_w2, int4_s_i2)\n",
    "\n",
    "int4_s_o1, int4_z_o1 = int4_s_i2, int4_z_i2\n",
    "\n",
    "int4_s_o2, int4_z_o2 = activation_scale_zero_point(outputs_float32, 16)\n",
    "\n",
    "\n",
    "model_int4 = Module()\n",
    "model_int4.add_module(FullyConnected(int4_w1.T, int4_b1, int4_s_w1, int4_s_i1, int4_s_o1, int4_z_i1, int4_z_o1, -8, 7), 'l1')\n",
    "model_int4.add_module(FullyConnected(int4_w2.T, int4_b2, int4_s_w2, int4_s_i2, int4_s_o2, int4_z_i2, int4_z_o2, -8, 7), 'l2')\n",
    "\n",
    "print(int4_w1.T.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:17:46.163298Z",
     "end_time": "2023-04-09T19:17:46.257749Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model int2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: 0.3333333333333333 \n",
      "z: -2.0\n",
      "s: 7.747121175130208 \n",
      "z: -2.0\n",
      "s: 22.12823994954427 \n",
      "z: 0.0\n"
     ]
    }
   ],
   "source": [
    "int2_s_w1, int2_z_w1, int2_w1 = weight_arr_quan(model.layers[0].get_weights()[0], -1, 1)\n",
    "int2_s_i1, int2_z_i1 = activation_scale_zero_point(train_images_float32, 4)\n",
    "int2_s_b1, int2_z_b1, int2_b1 = bias_arr_quan(model.layers[0].get_weights()[1], int2_s_w1, int2_s_i1)\n",
    "\n",
    "int2_s_w2, int2_z_w2, int2_w2 = weight_arr_quan(model.layers[1].get_weights()[0], -1, 1)\n",
    "int2_s_i2, int2_z_i2 = activation_scale_zero_point(intermediate_output_float32, 4)\n",
    "int2_s_b2, int2_z_b2, int2_b2 = bias_arr_quan(model.layers[1].get_weights()[1], int2_s_w2, int2_s_i2)\n",
    "\n",
    "int2_s_o1, int2_z_o1 = int2_s_i2, int2_z_i2\n",
    "\n",
    "int2_s_o2, int2_z_o2 = activation_scale_zero_point(outputs_float32, 4)\n",
    "\n",
    "\n",
    "model_int2 = Module()\n",
    "model_int2.add_module(FullyConnected(int2_w1.T, int2_b1, int2_s_w1, int2_s_i1, int2_s_o1, int2_z_i1, int2_z_o1, -2, 1), 'l1')\n",
    "model_int2.add_module(FullyConnected(int2_w2.T, int2_b2, int2_s_w2, int2_s_i2, int2_s_o2, int2_z_i2, int2_z_o2, -2, 1), 'l2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:17:46.257749Z",
     "end_time": "2023-04-09T19:17:46.367626Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare TFLite_int8, int8, int4 and int2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Initialize the interpreter\n",
    "import pathlib\n",
    "\n",
    "tflite_file = pathlib.Path('.\\models\\mnist_int8_tflite_model.tflite')\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "def run_tflite_model(interpreter, input):\n",
    "\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "\n",
    "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "    test_image = input / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "\n",
    "\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_index)\n",
    "\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:17:46.367626Z",
     "end_time": "2023-04-09T19:17:46.414470Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def evaluate_models(model_int8, model_int4, model_int2, model_int8_tf_path, eva_images_float32, eva_labels, path_to_save):\n",
    "    dif = np.array([0])\n",
    "    correct_int8 = 0\n",
    "    correct_int4 = 0\n",
    "    correct_int2 = 0\n",
    "    correct_int8_tf = 0\n",
    "\n",
    "    mistakes_int8 = np.array([])\n",
    "    mistakes_int4 = np.array([])\n",
    "    mistakes_int2 = np.array([])\n",
    "    mistakes_int8_tf = np.array([])\n",
    "\n",
    "    tflite_file = pathlib.Path(model_int8_tf_path)\n",
    "    interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    for i in range(eva_images_float32.shape[0]):\n",
    "\n",
    "        if i % 1000 == 0 and i != 0:\n",
    "            print(\"done \", i)\n",
    "\n",
    "        input_int8_tf = eva_images_float32[i]\n",
    "\n",
    "        input_int8 = eva_images_float32[i]\n",
    "        input_int8 = input_int8 / int8_s_i1 + int8_z_i1\n",
    "        input_int8 = np.expand_dims(input_int8, axis=0).astype(np.int8)\n",
    "\n",
    "        input_int4 = eva_images_float32[i]\n",
    "        input_int4 = input_int4 / int4_s_i1 + int4_z_i1\n",
    "        input_int4 = np.expand_dims(input_int4, axis=0).astype(np.int8)\n",
    "\n",
    "        input_int2 = eva_images_float32[i]\n",
    "        input_int2 = input_int2 / int2_s_i1 + int2_z_i1\n",
    "        input_int2 = np.expand_dims(input_int2, axis=0).astype(np.int8)\n",
    "\n",
    "\n",
    "        output_model_int8 = model_int8.forward(input_int8)\n",
    "        output_model_int4 = model_int4.forward(input_int4)\n",
    "        output_model_int2 = model_int2.forward(input_int2)\n",
    "        output_model_int8_tf = run_tflite_model(interpreter, input_int8_tf)\n",
    "\n",
    "        dif[0] += np.sum(np.abs(output_model_int8 - output_model_int8_tf))\n",
    "\n",
    "        answer_int8 = np.argmax(output_model_int8)\n",
    "        answer_int4 = np.argmax(output_model_int4)\n",
    "        answer_int2 = np.argmax(output_model_int2)\n",
    "        answer_int8_tf = np.argmax(output_model_int8_tf)\n",
    "\n",
    "        if answer_int8 == eva_labels[i]:\n",
    "            correct_int8 += 1\n",
    "        else:\n",
    "            mistakes_int8 = np.append(mistakes_int8, i)\n",
    "\n",
    "        if answer_int4 == eva_labels[i]:\n",
    "            correct_int4 += 1\n",
    "        else:\n",
    "            mistakes_int4 = np.append(mistakes_int4, i)\n",
    "\n",
    "        if answer_int2 == eva_labels[i]:\n",
    "            correct_int2 += 1\n",
    "        else:\n",
    "            mistakes_int2 = np.append(mistakes_int2, i)\n",
    "\n",
    "        if answer_int8_tf == eva_labels[i]:\n",
    "            correct_int8_tf += 1\n",
    "        else:\n",
    "            mistakes_int8_tf = np.append(mistakes_int8_tf, i)\n",
    "\n",
    "\n",
    "    np.save(path_to_save + '/array_dif_int8tf_int8_my-weights-scales-zpoints.npy', dif)\n",
    "    np.save(path_to_save + '/mistakes_int8.npy', mistakes_int8)\n",
    "    np.save(path_to_save + '/mistakes_int4.npy', mistakes_int4)\n",
    "    np.save(path_to_save + '/mistakes_int2.npy', mistakes_int2)\n",
    "    np.save(path_to_save + '/mistakes_int8_tf.npy', mistakes_int8_tf)\n",
    "\n",
    "    mistake_output = np.sum(dif) / eva_images_float32.shape[0]\n",
    "    mistake_value = mistake_output / 10\n",
    "\n",
    "    print(f'Mistake in output: {mistake_output}')\n",
    "    print(f'Mistake in value: {mistake_value}\\n')\n",
    "\n",
    "    print('Accuracy float32: ', model.evaluate(eva_images_float32, eva_labels)[1])\n",
    "    print('Accuracy int8 tf: ', correct_int8_tf / eva_images_float32.shape[0])\n",
    "    print('Accuracy int8   : ', correct_int8 / eva_images_float32.shape[0])\n",
    "    print('Accuracy int4   : ', correct_int4 / eva_images_float32.shape[0])\n",
    "    print('Accuracy int2   : ', correct_int2 / eva_images_float32.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:17:46.383251Z",
     "end_time": "2023-04-09T19:17:46.414470Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 672us/step - loss: 0.1665 - accuracy: 0.9532\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.1665320098400116, 0.9531999826431274]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(eva_images_float32, eva_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:17:46.398871Z",
     "end_time": "2023-04-09T19:17:46.750141Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# dif = np.load('mistakes_layer2_neurons20-10/array_dif_int8tf_int8my-weights-scales-zpoints.npy')\n",
    "# mistake_output = np.sum(dif) / eva_images_float32.shape[0]\n",
    "# mistake_value = mistake_output / 10\n",
    "#\n",
    "# print(f'Mistake in output: {mistake_output}')\n",
    "# print(f'Mistake in value: {mistake_value}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:17:46.750141Z",
     "end_time": "2023-04-09T19:17:46.768450Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:17:46.769502Z",
     "end_time": "2023-04-09T19:17:46.815918Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bigger nn model float32 500-500-500-10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2749 - accuracy: 0.9193 - val_loss: 0.1457 - val_accuracy: 0.9565\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1105 - accuracy: 0.9654 - val_loss: 0.1130 - val_accuracy: 0.9662\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0782 - accuracy: 0.9758 - val_loss: 0.0972 - val_accuracy: 0.9712\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0614 - accuracy: 0.9800 - val_loss: 0.0803 - val_accuracy: 0.9752\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0488 - accuracy: 0.9843 - val_loss: 0.0832 - val_accuracy: 0.9748\n",
      "Epoch 6/10\n",
      "362/938 [==========>...................] - ETA: 0s - loss: 0.0350 - accuracy: 0.9890"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9820\\1988350619.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m     \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0meva_images_float32\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0meva_labels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m )\n\u001B[0;32m     26\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\dp\\dp\\code\\openvino_notebooks_py37\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 65\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     66\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\dp\\dp\\code\\openvino_notebooks_py37\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1562\u001B[0m                         ):\n\u001B[0;32m   1563\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1564\u001B[1;33m                             \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1565\u001B[0m                             \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1566\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\dp\\dp\\code\\openvino_notebooks_py37\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\dp\\dp\\code\\openvino_notebooks_py37\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    878\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    879\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 880\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    881\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    882\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\dp\\dp\\code\\openvino_notebooks_py37\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    910\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    911\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 912\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_no_variable_creation_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    913\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_variable_creation_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    914\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\dp\\dp\\code\\openvino_notebooks_py37\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    133\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m    134\u001B[0m     return concrete_function._call_flat(\n\u001B[1;32m--> 135\u001B[1;33m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[0;32m    136\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    137\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\dp\\dp\\code\\openvino_notebooks_py37\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1744\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1745\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[1;32m-> 1746\u001B[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[0;32m   1747\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[0;32m   1748\u001B[0m         \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\dp\\dp\\code\\openvino_notebooks_py37\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    381\u001B[0m               \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    382\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 383\u001B[1;33m               ctx=ctx)\n\u001B[0m\u001B[0;32m    384\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    385\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[1;32md:\\dp\\dp\\code\\openvino_notebooks_py37\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     52\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[1;32m---> 53\u001B[1;33m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[0;32m     54\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(100, activation='relu', input_dim=input_size),\n",
    "        tf.keras.layers.Dense(100, activation='relu'),\n",
    "        tf.keras.layers.Dense(100, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "\n",
    "model = create_model()\n",
    "model.fit(\n",
    "    train_images_float32,\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_data=(eva_images_float32, eva_labels)\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:05:47.096069Z",
     "end_time": "2023-04-09T19:06:00.541373Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tflite_models_dir = pathlib.Path(\"models\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "float_weights_path = r\"./models/mnist_float_nn_tf_layers4_neurons_100-100-100-10/mnist_float_weights\"\n",
    "\n",
    "# Save the model:\n",
    "float_weights_model_file = tflite_models_dir / \"mnist_float_nn_tf_layers4_neurons_100-100-100-10/mnist_float_weights\"\n",
    "float_weights_model_file_index = tflite_models_dir / \"mnist_float_nn_tf_layers4_neurons_100-100-100-10/mnist_float_weights.index\"\n",
    "if not float_weights_model_file_index.is_file():\n",
    "    model.save_weights(float_weights_model_file)\n",
    "    print(\"Float weights saved to: \", float_weights_model_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:06:00.544324Z",
     "end_time": "2023-04-09T19:06:00.575600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.load_weights(float_weights_model_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:06:00.559966Z",
     "end_time": "2023-04-09T19:06:00.622521Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a new model that outputs the intermediate layer\n",
    "intermediate_model_1 = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
    "intermediate_model_2 = tf.keras.Model(inputs=model.input, outputs=model.layers[1].output)\n",
    "intermediate_model_3 = tf.keras.Model(inputs=model.input, outputs=model.layers[2].output)\n",
    "\n",
    "# Get the intermediate output for the entire input dataset\n",
    "intermediate_output_1_float32 = intermediate_model_1.predict(train_images_float32)\n",
    "intermediate_output_2_float32 = intermediate_model_2.predict(train_images_float32)\n",
    "intermediate_output_3_float32 = intermediate_model_3.predict(train_images_float32)\n",
    "\n",
    "outputs_float32 = model.predict(train_images_float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:06:00.622521Z",
     "end_time": "2023-04-09T19:06:06.979062Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bigger nn model int8 tf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in train_images_float32:\n",
    "        yield [input_value]\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Set the input and output tensors to int8\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:06:06.979062Z",
     "end_time": "2023-04-09T19:06:08.953118Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tflite_models_dir = pathlib.Path(\"models\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "model_path = r\"models/mnist_int8_tflite_model_layers4_neurons100-100-100-10\"\n",
    "\n",
    "# Save the model:\n",
    "int8_tflite_model_file = tflite_models_dir / \"mnist_int8_tflite_model_layers4_neurons100-100-100-10.tflite\"\n",
    "if not int8_tflite_model_file.is_file():\n",
    "    int8_tflite_model_file.write_bytes(tflite_model_quant)\n",
    "    print(\"Model saved to: \", int8_tflite_model_file)\n",
    "\n",
    "netron.start(model_path + r'.tflite')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:06:08.921629Z",
     "end_time": "2023-04-09T19:06:09.031256Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tflite_file = pathlib.Path('.\\models\\mnist_int8_tflite_model_layers4_neurons100-100-100-10.tflite')\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "interpreter.allocate_tensors()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:06:09.094181Z",
     "end_time": "2023-04-09T19:06:09.157132Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bigger nn model int8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "int8_s_w1, int8_z_w1, int8_w1 = weight_arr_quan(model.layers[0].get_weights()[0], -127, 127)\n",
    "int8_s_i1, int8_z_i1 = activation_scale_zero_point(train_images_float32, 256)\n",
    "int8_s_b1, int8_z_b1, int8_b1 = bias_arr_quan(model.layers[0].get_weights()[1], int8_s_w1, int8_s_i1)\n",
    "\n",
    "int8_s_w2, int8_z_w2, int8_w2 = weight_arr_quan(model.layers[1].get_weights()[0], -127, 127)\n",
    "int8_s_i2, int8_z_i2 = activation_scale_zero_point(intermediate_output_1_float32, 256)\n",
    "int8_s_b2, int8_z_b2, int8_b2 = bias_arr_quan(model.layers[1].get_weights()[1], int8_s_w2, int8_s_i2)\n",
    "\n",
    "int8_s_w3, int8_z_w3, int8_w3 = weight_arr_quan(model.layers[2].get_weights()[0], -127, 127)\n",
    "int8_s_i3, int8_z_i3 = activation_scale_zero_point(intermediate_output_2_float32, 256)\n",
    "int8_s_b3, int8_z_b3, int8_b3 = bias_arr_quan(model.layers[2].get_weights()[1], int8_s_w3, int8_s_i3)\n",
    "\n",
    "int8_s_w4, int8_z_w4, int8_w4 = weight_arr_quan(model.layers[3].get_weights()[0], -127, 127)\n",
    "int8_s_i4, int8_z_i4 = activation_scale_zero_point(intermediate_output_3_float32, 256)\n",
    "int8_s_b4, int8_z_b4, int8_b4 = bias_arr_quan(model.layers[3].get_weights()[1], int8_s_w4, int8_s_i4)\n",
    "\n",
    "int8_s_o1, int8_z_o1 = int8_s_i2, int8_z_i2\n",
    "int8_s_o2, int8_z_o2 = int8_s_i3, int8_z_i3\n",
    "int8_s_o3, int8_z_o3 = int8_s_i4, int8_z_i4\n",
    "int8_s_o4, int8_z_o4 = activation_scale_zero_point(outputs_float32, 256)\n",
    "\n",
    "model_int8 = Module()\n",
    "model_int8.add_module(FullyConnected(int8_w1.T, int8_b1, int8_s_w1, int8_s_i1, int8_s_o1, int8_z_i1, int8_z_o1, -128, 127), 'l1')\n",
    "model_int8.add_module(FullyConnected(int8_w2.T, int8_b2, int8_s_w2, int8_s_i2, int8_s_o2, int8_z_i2, int8_z_o2, -128, 127), 'l2')\n",
    "model_int8.add_module(FullyConnected(int8_w3.T, int8_b3, int8_s_w3, int8_s_i3, int8_s_o3, int8_z_i3, int8_z_o3, -128, 127), 'l3')\n",
    "model_int8.add_module(FullyConnected(int8_w4.T, int8_b4, int8_s_w4, int8_s_i4, int8_s_o4, int8_z_i4, int8_z_o4, -128, 127), 'l4')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:06:09.094181Z",
     "end_time": "2023-04-09T19:06:09.622082Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bigger nn model int4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "int4_s_w1, int4_z_w1, int4_w1 = weight_arr_quan(model.layers[0].get_weights()[0], -7, 7)\n",
    "int4_s_i1, int4_z_i1 = activation_scale_zero_point(train_images_float32, 16)\n",
    "int4_s_b1, int4_z_b1, int4_b1 = bias_arr_quan(model.layers[0].get_weights()[1], int4_s_w1, int4_s_i1)\n",
    "\n",
    "int4_s_w2, int4_z_w2, int4_w2 = weight_arr_quan(model.layers[1].get_weights()[0], -7, 7)\n",
    "int4_s_i2, int4_z_i2 = activation_scale_zero_point(intermediate_output_1_float32, 16)\n",
    "int4_s_b2, int4_z_b2, int4_b2 = bias_arr_quan(model.layers[1].get_weights()[1], int4_s_w2, int4_s_i2)\n",
    "\n",
    "int4_s_w3, int4_z_w3, int4_w3 = weight_arr_quan(model.layers[2].get_weights()[0], -7, 7)\n",
    "int4_s_i3, int4_z_i3 = activation_scale_zero_point(intermediate_output_2_float32, 16)\n",
    "int4_s_b3, int4_z_b3, int4_b3 = bias_arr_quan(model.layers[2].get_weights()[1], int4_s_w3, int4_s_i3)\n",
    "\n",
    "int4_s_w4, int4_z_w4, int4_w4 = weight_arr_quan(model.layers[3].get_weights()[0], -7, 7)\n",
    "int4_s_i4, int4_z_i4 = activation_scale_zero_point(intermediate_output_3_float32, 16)\n",
    "int4_s_b4, int4_z_b4, int4_b4 = bias_arr_quan(model.layers[3].get_weights()[1], int4_s_w4, int4_s_i4)\n",
    "\n",
    "int4_s_o1, int4_z_o1 = int4_s_i2, int4_z_i2\n",
    "int4_s_o2, int4_z_o2 = int4_s_i3, int4_z_i3\n",
    "int4_s_o3, int4_z_o3 = int4_s_i4, int4_z_i4\n",
    "int4_s_o4, int4_z_o4 = activation_scale_zero_point(outputs_float32, 16)\n",
    "\n",
    "model_int4 = Module()\n",
    "model_int4.add_module(FullyConnected(int4_w1.T, int4_b1, int4_s_w1, int4_s_i1, int4_s_o1, int4_z_i1, int4_z_o1, -8, 7), 'l1')\n",
    "model_int4.add_module(FullyConnected(int4_w2.T, int4_b2, int4_s_w2, int4_s_i2, int4_s_o2, int4_z_i2, int4_z_o2, -8, 7), 'l2')\n",
    "model_int4.add_module(FullyConnected(int4_w3.T, int4_b3, int4_s_w3, int4_s_i3, int4_s_o3, int4_z_i3, int4_z_o3, -8, 7), 'l3')\n",
    "model_int4.add_module(FullyConnected(int4_w4.T, int4_b4, int4_s_w4, int4_s_i4, int4_s_o4, int4_z_i4, int4_z_o4, -8, 7), 'l4')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:06:09.622082Z",
     "end_time": "2023-04-09T19:06:10.289132Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bigger nn model int2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "int2_s_w1, int2_z_w1, int2_w1 = weight_arr_quan(model.layers[0].get_weights()[0], -1, 1)\n",
    "int2_s_i1, int2_z_i1 = activation_scale_zero_point(train_images_float32, 4)\n",
    "int2_s_b1, int2_z_b1, int2_b1 = bias_arr_quan(model.layers[0].get_weights()[1], int2_s_w1, int2_s_i1)\n",
    "\n",
    "int2_s_w2, int2_z_w2, int2_w2 = weight_arr_quan(model.layers[1].get_weights()[0], -1, 1)\n",
    "int2_s_i2, int2_z_i2 = activation_scale_zero_point(intermediate_output_1_float32, 4)\n",
    "int2_s_b2, int2_z_b2, int2_b2 = bias_arr_quan(model.layers[1].get_weights()[1], int2_s_w2, int2_s_i2)\n",
    "\n",
    "int2_s_w3, int2_z_w3, int2_w3 = weight_arr_quan(model.layers[2].get_weights()[0], -1, 1)\n",
    "int2_s_i3, int2_z_i3 = activation_scale_zero_point(intermediate_output_2_float32, 4)\n",
    "int2_s_b3, int2_z_b3, int2_b3 = bias_arr_quan(model.layers[2].get_weights()[1], int2_s_w3, int2_s_i3)\n",
    "\n",
    "int2_s_w4, int2_z_w4, int2_w4 = weight_arr_quan(model.layers[3].get_weights()[0], -1, 1)\n",
    "int2_s_i4, int2_z_i4 = activation_scale_zero_point(intermediate_output_3_float32, 4)\n",
    "int2_s_b4, int2_z_b4, int2_b4 = bias_arr_quan(model.layers[3].get_weights()[1], int2_s_w4, int2_s_i4)\n",
    "\n",
    "int2_s_o1, int2_z_o1 = int2_s_i2, int2_z_i2\n",
    "int2_s_o2, int2_z_o2 = int2_s_i3, int2_z_i3\n",
    "int2_s_o3, int2_z_o3 = int2_s_i4, int2_z_i4\n",
    "int2_s_o4, int2_z_o4 = activation_scale_zero_point(outputs_float32, 4)\n",
    "\n",
    "model_int2 = Module()\n",
    "model_int2.add_module(FullyConnected(int2_w1.T, int2_b1, int2_s_w1, int2_s_i1, int2_s_o1, int2_z_i1, int2_z_o1, -2, 1), 'l1')\n",
    "model_int2.add_module(FullyConnected(int2_w2.T, int2_b2, int2_s_w2, int2_s_i2, int2_s_o2, int2_z_i2, int2_z_o2, -2, 1), 'l2')\n",
    "model_int2.add_module(FullyConnected(int2_w3.T, int2_b3, int2_s_w3, int2_s_i3, int2_s_o3, int2_z_i3, int2_z_o3, -2, 1), 'l3')\n",
    "model_int2.add_module(FullyConnected(int2_w4.T, int2_b4, int2_s_w4, int2_s_i4, int2_s_o4, int2_z_i4, int2_z_o4, -2, 1), 'l4')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T19:06:10.289132Z",
     "end_time": "2023-04-09T19:06:10.933532Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "dif = np.array([0])\n",
    "correct_int8 = 0\n",
    "correct_int4 = 0\n",
    "correct_int2 = 0\n",
    "correct_int8_tf = 0\n",
    "\n",
    "mistakes_int8 = np.array([])\n",
    "mistakes_int4 = np.array([])\n",
    "mistakes_int2 = np.array([])\n",
    "mistakes_int8_tf = np.array([])\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    if i == 0:\n",
    "        start_time = time.time()\n",
    "\n",
    "    input_int8_tf = eva_images_float32[i]\n",
    "\n",
    "    input_int8 = eva_images_float32[i]\n",
    "    input_int8 = input_int8 / int8_s_i1 + int8_z_i1\n",
    "    input_int8 = np.expand_dims(input_int8, axis=0).astype(np.int8)\n",
    "\n",
    "    input_int4 = eva_images_float32[i]\n",
    "    input_int4 = input_int4 / int4_s_i1 + int4_z_i1\n",
    "    input_int4 = np.expand_dims(input_int4, axis=0).astype(np.int8)\n",
    "\n",
    "    print(input_int4.shape)\n",
    "\n",
    "    input_int2 = eva_images_float32[i]\n",
    "    input_int2 = input_int2 / int2_s_i1 + int2_z_i1\n",
    "    input_int2 = np.expand_dims(input_int2, axis=0).astype(np.int8)\n",
    "\n",
    "\n",
    "    output_model_int8 = model_int8.forward(input_int8)\n",
    "    output_model_int4 = model_int4.forward(input_int4)\n",
    "    output_model_int2 = model_int2.forward(input_int2)\n",
    "    output_model_int8_tf = run_tflite_model(interpreter, input_int8_tf)\n",
    "\n",
    "    dif[0] += np.sum(np.abs(output_model_int8 - output_model_int8_tf))\n",
    "\n",
    "    answer_int8 = np.argmax(output_model_int8)\n",
    "    answer_int4 = np.argmax(output_model_int4)\n",
    "    answer_int2 = np.argmax(output_model_int2)\n",
    "    answer_int8_tf = np.argmax(output_model_int8_tf)\n",
    "\n",
    "    if answer_int8 == eva_labels[i]:\n",
    "        correct_int8 += 1\n",
    "    else:\n",
    "        mistakes_int8 = np.append(mistakes_int8, i)\n",
    "\n",
    "    if answer_int4 == eva_labels[i]:\n",
    "        correct_int4 += 1\n",
    "    else:\n",
    "        mistakes_int4 = np.append(mistakes_int4, i)\n",
    "\n",
    "    if answer_int2 == eva_labels[i]:\n",
    "        correct_int2 += 1\n",
    "    else:\n",
    "        mistakes_int2 = np.append(mistakes_int2, i)\n",
    "\n",
    "    if answer_int8_tf == eva_labels[i]:\n",
    "        correct_int8_tf += 1\n",
    "    else:\n",
    "        mistakes_int8_tf = np.append(mistakes_int8_tf, i)\n",
    "\n",
    "    if i == 0:\n",
    "        end_time = time.time()\n",
    "        print('time for 1 image: ', end_time - start_time)\n",
    "\n",
    "\n",
    "np.save('mistakes_layers4_neurons500-500-500-10/array_dif_int8tf_int8_my-weights-scales-zpoints.npy', dif)\n",
    "np.save('mistakes_layers4_neurons500-500-500-10/mistakes_int8.npy', mistakes_int8)\n",
    "np.save('mistakes_layers4_neurons500-500-500-10/mistakes_int4.npy', mistakes_int4)\n",
    "np.save('mistakes_layers4_neurons500-500-500-10/mistakes_int2.npy', mistakes_int2)\n",
    "np.save('mistakes_layers4_neurons500-500-500-10/mistakes_int8_tf.npy', mistakes_int8_tf)\n",
    "\n",
    "mistake_output = np.sum(dif) / eva_images_float32.shape[0]\n",
    "mistake_value = mistake_output / 10\n",
    "\n",
    "print(f'Mistake in output: {mistake_output}')\n",
    "print(f'Mistake in value: {mistake_value}\\n')\n",
    "\n",
    "print('Accuracy float32: ', model.evaluate(eva_images_float32, eva_labels)[1])\n",
    "print('Accuracy int8 tf: ', correct_int8_tf / eva_images_float32.shape[0])\n",
    "print('Accuracy int8   : ', correct_int8 / eva_images_float32.shape[0])\n",
    "print('Accuracy int4   : ', correct_int4 / eva_images_float32.shape[0])\n",
    "print('Accuracy int2   : ', correct_int2 / eva_images_float32.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T14:34:22.153372Z",
     "end_time": "2023-04-08T14:34:28.656085Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PCA reduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.86) # 64 eva 8-bit accuracy:  0.9564 4-bit accuracy:  0.7812\n",
    "# pca = PCA(n_components = 0.74) # 32 eva 8-bit accuracy:  0.9448 4-bit accuracy:  0.7912\n",
    "# pca = PCA(n_components = 0.59) # 16 eva 8-bit accuracy:  0.9292 4-bit accuracy:  0.8102\n",
    "# pca = PCA(n_components = 0.43) # 8 eva 8-bit accuracy:  0.8717 4-bit accuracy:  0.7355\n",
    "# pca = PCA(n_components = 0.28) # 4 eva 8-bit accuracy:  0.6484 4-bit accuracy:  0.487\n",
    "train_reduced = pca.fit_transform(train_images_float32)\n",
    "eva_reduced = pca.transform(eva_images_float32)\n",
    "print(train_reduced.shape)\n",
    "print(eva_reduced.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T18:29:08.202978Z",
     "end_time": "2023-04-08T18:29:13.309007Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_size = train_reduced.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T18:29:13.311006Z",
     "end_time": "2023-04-08T18:29:13.369539Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(20, activation='relu', input_dim=input_size),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "\n",
    "model = create_model()\n",
    "model.fit(\n",
    "    train_reduced,\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_data=(eva_reduced, eva_labels)\n",
    ")\n",
    "\n",
    "model.evaluate(eva_reduced, eva_labels)\n",
    "\n",
    "# Define a new model that outputs the intermediate layer\n",
    "intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
    "\n",
    "# Get the intermediate output for the entire input dataset\n",
    "intermediate_output_float32 = intermediate_model.predict(train_reduced)\n",
    "\n",
    "outputs_float32 = model.predict(train_reduced)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T18:29:13.331006Z",
     "end_time": "2023-04-08T18:29:26.197704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "int8_s_w1, int8_z_w1, int8_w1 = weight_arr_quan(model.layers[0].get_weights()[0], -127, 127)\n",
    "int8_s_i1, int8_z_i1 = activation_scale_zero_point(train_reduced, 256)\n",
    "int8_s_b1, int8_z_b1, int8_b1 = bias_arr_quan(model.layers[0].get_weights()[1], int8_s_w1, int8_s_i1)\n",
    "\n",
    "int8_s_w2, int8_z_w2, int8_w2 = weight_arr_quan(model.layers[1].get_weights()[0], -127, 127)\n",
    "int8_s_i2, int8_z_i2 = activation_scale_zero_point(intermediate_output_float32, 256)\n",
    "int8_s_b2, int8_z_b2, int8_b2 = bias_arr_quan(model.layers[1].get_weights()[1], int8_s_w2, int8_s_i2)\n",
    "\n",
    "int8_s_o1, int8_z_o1 = int8_s_i2, int8_z_i2\n",
    "\n",
    "int8_s_o2, int8_z_o2 = activation_scale_zero_point(outputs_float32, 256)\n",
    "\n",
    "\n",
    "model_int8 = Module()\n",
    "model_int8.add_module(FullyConnected(int8_w1.T, int8_b1, int8_s_w1, int8_s_i1, int8_s_o1, int8_z_i1, int8_z_o1, -128, 127), 'l1')\n",
    "model_int8.add_module(FullyConnected(int8_w2.T, int8_b2, int8_s_w2, int8_s_i2, int8_s_o2, int8_z_i2, int8_z_o2, -128, 127), 'l2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T18:29:26.197704Z",
     "end_time": "2023-04-08T18:29:26.213462Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "int4_s_w1, int4_z_w1, int4_w1 = weight_arr_quan(model.layers[0].get_weights()[0], -7, 7)\n",
    "int4_s_i1, int4_z_i1 = activation_scale_zero_point(train_reduced, 16)\n",
    "int4_s_b1, int4_z_b1, int4_b1 = bias_arr_quan(model.layers[0].get_weights()[1], int4_s_w1, int4_s_i1)\n",
    "\n",
    "int4_s_w2, int4_z_w2, int4_w2 = weight_arr_quan(model.layers[1].get_weights()[0], -7, 7)\n",
    "int4_s_i2, int4_z_i2 = activation_scale_zero_point(intermediate_output_float32, 16)\n",
    "int4_s_b2, int4_z_b2, int4_b2 = bias_arr_quan(model.layers[1].get_weights()[1], int4_s_w2, int4_s_i2)\n",
    "\n",
    "int4_s_o1, int4_z_o1 = int4_s_i2, int4_z_i2\n",
    "\n",
    "int4_s_o2, int4_z_o2 = activation_scale_zero_point(outputs_float32, 16)\n",
    "\n",
    "\n",
    "model_int4 = Module()\n",
    "model_int4.add_module(FullyConnected(int4_w1.T, int4_b1, int4_s_w1, int4_s_i1, int4_s_o1, int4_z_i1, int4_z_o1, -8, 7), 'l1')\n",
    "model_int4.add_module(FullyConnected(int4_w2.T, int4_b2, int4_s_w2, int4_s_i2, int4_s_o2, int4_z_i2, int4_z_o2, -8, 7), 'l2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T18:29:26.213462Z",
     "end_time": "2023-04-08T18:29:26.260347Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_accuracy(model8, model4, test_images, test_labels):\n",
    "    correct4 = 0\n",
    "    correct8 = 0\n",
    "    for i in range(len(test_images)):\n",
    "\n",
    "        input_int8 = test_images[i]\n",
    "        input_int8 = input_int8 / int8_s_i1 + int8_z_i1\n",
    "        input_int8 = np.expand_dims(input_int8, axis=0).astype(np.int8)\n",
    "\n",
    "        input_int4 = test_images[i]\n",
    "        input_int4 = input_int4 / int4_s_i1 + int4_z_i1\n",
    "        input_int4 = np.expand_dims(input_int4, axis=0).astype(np.int8)\n",
    "\n",
    "        output8 = model8.forward(input_int8)\n",
    "        output4 = model4.forward(input_int4)\n",
    "\n",
    "        if np.argmax(output4) == test_labels[i]:\n",
    "            correct4 += 1\n",
    "        if np.argmax(output8) == test_labels[i]:\n",
    "            correct8 += 1\n",
    "\n",
    "    print('8-bit accuracy: ', correct8 / test_images.shape[0], '4-bit accuracy: ', correct4 / test_images.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T18:29:26.229071Z",
     "end_time": "2023-04-08T18:29:26.260347Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(test_accuracy(model_int8,model_int4, eva_reduced, eva_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T18:29:26.244657Z",
     "end_time": "2023-04-08T18:29:50.431683Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2D array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "two_d_array = []\n",
    "for i in range(5):\n",
    "    row = [i] * (i+1)   # create a row with i elements\n",
    "    two_d_array.append(row)  # add the row to the 2D array\n",
    "\n",
    "print(two_d_array)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T19:55:01.503552Z",
     "end_time": "2023-04-08T19:55:01.519304Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        try:\n",
    "            print(\"try: \", two_d_array[i][j])\n",
    "        except:\n",
    "            try:\n",
    "                print(\"except: \", two_d_array[j][i])\n",
    "            except:\n",
    "                print(\"except: error\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T19:55:02.326781Z",
     "end_time": "2023-04-08T19:55:02.338610Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create an empty NumPy array\n",
    "arr = np.zeros((5,), dtype=np.ndarray)\n",
    "\n",
    "# assign a list with different lengths to the first element of the array\n",
    "arr[0] = np.array([1])\n",
    "arr[1] = np.array([1, 2])\n",
    "arr[2] = np.array([1, 2, 3])\n",
    "arr[3] = np.array([1, 2, 3, 4])\n",
    "arr[4] = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(arr)\n",
    "# np.save('arr.npy', arr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T20:23:02.294438Z",
     "end_time": "2023-04-08T20:23:02.308747Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        try:\n",
    "            print(\"try: \", arr[i][j])\n",
    "        except:\n",
    "            try:\n",
    "                print(\"except: \", arr[j][i])\n",
    "            except:\n",
    "                print(\"except: error\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T20:23:03.878600Z",
     "end_time": "2023-04-08T20:23:03.894226Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
